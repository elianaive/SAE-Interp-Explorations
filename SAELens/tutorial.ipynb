{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sae-lens in c:\\users\\elian\\miniconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformer-lens in c:\\users\\elian\\miniconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: circuitsvis in c:\\users\\elian\\miniconda3\\lib\\site-packages (1.43.2)\n",
      "Requirement already satisfied: automated-interpretability<1.0.0,>=0.0.5 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (0.0.6)\n",
      "Requirement already satisfied: babe<0.0.8,>=0.0.7 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (0.0.7)\n",
      "Requirement already satisfied: datasets<3.0.0,>=2.17.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (2.21.0)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.8.3 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (3.9.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (0.1.7)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (3.9.1)\n",
      "Requirement already satisfied: plotly<6.0.0,>=5.19.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (5.24.1)\n",
      "Requirement already satisfied: plotly-express<0.5.0,>=0.4.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (0.4.1)\n",
      "Requirement already satisfied: pytest-profiling<2.0.0,>=1.7.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (1.8.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (1.0.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.0.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (26.0.0)\n",
      "Requirement already satisfied: safetensors<0.5.0,>=0.4.2 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (0.4.5)\n",
      "Requirement already satisfied: simple-parsing<0.2.0,>=0.1.6 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (0.1.6)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (4.46.3)\n",
      "Requirement already satisfied: typer<0.13.0,>=0.12.3 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (4.12.2)\n",
      "Requirement already satisfied: zstandard<0.23.0,>=0.22.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sae-lens) (0.22.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (1.1.1)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (0.0.3)\n",
      "Requirement already satisfied: einops>=0.6.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (0.8.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (0.2.36)\n",
      "Requirement already satisfied: numpy>=1.26 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (2.2.3)\n",
      "Requirement already satisfied: rich>=12.6.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (13.9.4)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (0.2.0)\n",
      "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (2.4.1+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (4.67.0)\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (4.4.1)\n",
      "Requirement already satisfied: wandb>=0.13.5 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformer-lens) (0.18.7)\n",
      "Requirement already satisfied: importlib-metadata>=5.1.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from circuitsvis) (8.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from accelerate>=0.23.0->transformer-lens) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from accelerate>=0.23.0->transformer-lens) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\elian\\miniconda3\\lib\\site-packages (from accelerate>=0.23.0->transformer-lens) (6.0.0)\n",
      "Requirement already satisfied: blobfile<3.0.0,>=2.1.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2.1.1)\n",
      "Requirement already satisfied: boostedblob<0.16.0,>=0.15.3 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.15.5)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.10.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.10.12)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.5.2)\n",
      "Requirement already satisfied: tiktoken<0.7.0,>=0.6.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.6.0)\n",
      "Requirement already satisfied: py2store in c:\\users\\elian\\miniconda3\\lib\\site-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.20)\n",
      "Requirement already satisfied: graze in c:\\users\\elian\\miniconda3\\lib\\site-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.27)\n",
      "Requirement already satisfied: filelock in c:\\users\\elian\\miniconda3\\lib\\site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\elian\\miniconda3\\lib\\site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\elian\\miniconda3\\lib\\site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.17.1->sae-lens) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\elian\\miniconda3\\lib\\site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.11.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.20.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (2.9.0)\n",
      "Requirement already satisfied: traitlets in c:\\users\\elian\\miniconda3\\lib\\site-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens) (5.14.3)\n",
      "Requirement already satisfied: click in c:\\users\\elian\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\elian\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (2024.11.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from pandas>=1.1.5->transformer-lens) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from pandas>=1.1.5->transformer-lens) (2024.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from plotly<6.0.0,>=5.19.0->sae-lens) (9.0.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.14.4)\n",
      "Requirement already satisfied: scipy>=0.18 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (1.14.1)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.5.6)\n",
      "Requirement already satisfied: six in c:\\users\\elian\\miniconda3\\lib\\site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.16.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\elian\\miniconda3\\lib\\site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (8.3.4)\n",
      "Requirement already satisfied: gprof2dot in c:\\users\\elian\\miniconda3\\lib\\site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2024.6.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from rich>=12.6.0->transformer-lens) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from rich>=12.6.0->transformer-lens) (2.18.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from simple-parsing<0.2.0,>=0.1.6->sae-lens) (0.16)\n",
      "Requirement already satisfied: sympy in c:\\users\\elian\\miniconda3\\lib\\site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\elian\\miniconda3\\lib\\site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\elian\\miniconda3\\lib\\site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\elian\\miniconda3\\lib\\site-packages (from tqdm>=4.64.1->transformer-lens) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.1->sae-lens) (0.20.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from typer<0.13.0,>=0.12.3->sae-lens) (1.5.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from wandb>=0.13.5->transformer-lens) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from wandb>=0.13.5->transformer-lens) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\elian\\miniconda3\\lib\\site-packages (from wandb>=0.13.5->transformer-lens) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from wandb>=0.13.5->transformer-lens) (5.28.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from wandb>=0.13.5->transformer-lens) (2.18.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\elian\\miniconda3\\lib\\site-packages (from wandb>=0.13.5->transformer-lens) (1.3.4)\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.21.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2.1.0)\n",
      "Requirement already satisfied: lxml~=4.9 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (4.9.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.17.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens) (4.0.11)\n",
      "Requirement already satisfied: anyio in c:\\users\\elian\\miniconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\elian\\miniconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\elian\\miniconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\elian\\miniconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\elian\\miniconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from requests>=2.32.2->datasets<3.0.0,>=2.17.1->sae-lens) (2.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=1.2.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.5.0)\n",
      "Requirement already satisfied: dol in c:\\users\\elian\\miniconda3\\lib\\site-packages (from graze->babe<0.0.8,>=0.0.7->sae-lens) (0.2.89)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (2.1.5)\n",
      "Requirement already satisfied: config2py in c:\\users\\elian\\miniconda3\\lib\\site-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (0.1.36)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\elian\\miniconda3\\lib\\site-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (6.4.5)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\elian\\miniconda3\\lib\\site-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens) (5.0.1)\n",
      "Requirement already satisfied: i2 in c:\\users\\elian\\miniconda3\\lib\\site-packages (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens) (0.1.38)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # import google.colab # type: ignore\n",
    "    # from google.colab import output\n",
    "    %pip install sae-lens transformer-lens circuitsvis\n",
    "except:\n",
    "    from IPython import get_ipython  # type: ignore\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elian\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"tiny-stories-1L-21M\"\n",
    ")  # This will wrap huggingface models and has lots of nice utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time there was a open harbor. The cove was so clean and cleaning. It was it ready to be used again, use the magic one to turn tiny crabs on the other. It was a fun idea, it decided to turn it on.\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Once upon a time there were two people who lived in a big bush. The panda felt sad because life seemed so far away. He wanted everyone to hear him say things to him.\\n\\nOne day, he decided to do something hard. He went to the'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Once upon a time, an owl named Millie had a silly idea. She wanted to care for the butterflies. So she got a stick and flew all around her head. Finally she found a big flower and flew up into the air!\\n\\nShe was so happy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Once upon a time in a big city, travels across one sunny day. On a holiday, Jack heard some strange noises. He looked around and started to walk away.\\n\\nHe walked and walked until he came to a big door. He jumped in and and he'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Once upon a time, there was a little girl named Daisy. Daisy liked to play outside in the sun. One day, Daisy went outside to play games with her mommy and Daddy. Every spring, Daisy would get dressed and go outside.\\n\\nBut the weather'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    display(\n",
    "        model.generate(\n",
    "            \"Once upon a time\",\n",
    "            stop_at_eos=False,  # avoids a bug on MPS\n",
    "            temperature=1,\n",
    "            verbose=False,\n",
    "            max_new_tokens=50,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'Once', ' upon', ' a', ' time', ',', ' there', ' was', ' a', ' little', ' girl', ' named', ' Lily', '.', ' She', ' lived', ' in', ' a', ' big', ',', ' happy', ' little', ' town', '.', ' On', ' her', ' big', ' adventure', ',']\n",
      "Tokenized answer: [' Lily']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.82</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.62</span><span style=\"font-weight: bold\">% Token: | Lily|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.82\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m8.62\u001b[0m\u001b[1m% Token: | Lily|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 21.00 Prob: 76.18% Token: | she|\n",
      "Top 1th token. Logit: 18.82 Prob:  8.62% Token: | Lily|\n",
      "Top 2th token. Logit: 18.16 Prob:  4.45% Token: | there|\n",
      "Top 3th token. Logit: 17.00 Prob:  1.39% Token: | the|\n",
      "Top 4th token. Logit: 16.76 Prob:  1.10% Token: | her|\n",
      "Top 5th token. Logit: 16.61 Prob:  0.94% Token: | all|\n",
      "Top 6th token. Logit: 16.56 Prob:  0.90% Token: | everyone|\n",
      "Top 7th token. Logit: 16.04 Prob:  0.53% Token: | things|\n",
      "Top 8th token. Logit: 16.04 Prob:  0.53% Token: | they|\n",
      "Top 9th token. Logit: 16.03 Prob:  0.53% Token: | people|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Lily'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Lily'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "# Test the model with a prompt\n",
    "test_prompt(\n",
    "    \"Once upon a time, there was a little girl named Lily. She lived in a big, happy little town. On her big adventure,\",\n",
    "    \" Lily\",\n",
    "    model,\n",
    "    prepend_space_to_answer=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-e8cf7187-43db\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-e8cf7187-43db\",\n",
       "      TokenLogProbs,\n",
       "      {\"prompt\": [\"<|endoftext|>\", \"Hi\", \",\", \" how\", \" are\", \" you\", \" doing\", \" this\", \"?\", \" I\", \"'m\", \" really\", \" enjoying\", \" your\", \" posts\"], \"topKLogProbs\": [[-0.02023809589445591, -6.1045026779174805, -7.070319175720215, -7.073500633239746, -7.178889274597168, -7.389695167541504, -7.525322914123535, -7.588588714599609, -7.763060569763184, -8.22431468963623], [-1.1883898973464966, -3.4683732986450195, -3.4808359146118164, -3.4896116256713867, -3.500030517578125, -3.554368019104004, -4.017880439758301, -4.030543327331543, -4.298168182373047, -4.418177604675293], [-2.920142650604248, -3.3794875144958496, -3.4266772270202637, -3.531759738922119, -3.9561686515808105, -4.2560553550720215, -4.443936824798584, -4.444850444793701, -4.55997896194458, -4.583315372467041], [-0.9917515516281128, -2.92867374420166, -3.2575254440307617, -3.3179845809936523, -3.4740543365478516, -3.641909599304199, -3.8675012588500977, -3.868638038635254, -3.891712188720703, -4.0052900314331055], [-0.03712337464094162, -4.68334436416626, -4.972261905670166, -5.85427713394165, -5.942128658294678, -6.3880391120910645, -6.39408540725708, -6.49857759475708, -6.593416690826416, -7.869242191314697], [-0.23486194014549255, -2.335432529449463, -2.947481632232666, -5.0528035163879395, -5.078577518463135, -5.102743625640869, -5.11631441116333, -5.737268924713135, -5.768452167510986, -5.89376974105835], [-0.44885262846946716, -2.0767040252685547, -3.4335803985595703, -3.645082473754883, -3.7033824920654297, -4.046270370483398, -4.096990585327148, -4.209768295288086, -4.5189666748046875, -4.961885452270508], [-0.46094536781311035, -2.737755060195923, -3.158905267715454, -3.6868040561676025, -4.416438102722168, -4.448530197143555, -4.571943283081055, -4.669158935546875, -4.695380210876465, -4.748210906982422], [-0.9866101741790771, -1.8349740505218506, -2.4600236415863037, -2.511583089828491, -3.1156346797943115, -3.4194858074188232, -3.520374059677124, -3.8049867153167725, -4.003087043762207, -4.258258819580078], [-1.3091977834701538, -1.6338876485824585, -1.7868112325668335, -2.631619930267334, -3.46028470993042, -3.6158385276794434, -4.0200419425964355, -4.0932841300964355, -4.177457332611084, -4.309239864349365], [-1.995237112045288, -2.5565383434295654, -2.6455514430999756, -2.8948304653167725, -3.1104400157928467, -3.394559621810913, -3.7311055660247803, -3.8203370571136475, -3.9678990840911865, -4.026362419128418], [-1.0431073904037476, -1.959464430809021, -3.0507826805114746, -3.421494960784912, -3.480130672454834, -3.4898390769958496, -3.6020007133483887, -4.33250093460083, -4.492428302764893, -4.51763391494751], [-1.5123966932296753, -2.020277976989746, -2.223280906677246, -2.249321937561035, -3.3765172958374023, -3.9217042922973633, -3.979830741882324, -4.199248313903809, -4.265368461608887, -4.661585807800293], [-3.188746213912964, -3.1920535564422607, -3.4252212047576904, -3.4941909313201904, -3.732595205307007, -3.735314130783081, -3.7357099056243896, -3.8339641094207764, -4.233706474304199, -4.265704154968262]], \"topKTokens\": [[\"\\n\", \",\", \"Words\", \"Summary\", \"\\n\\n\", \"<|endoftext|>\", \" \", \"Features\", \"Random\", \" the\"], [\",\", \" Tim\", \" bird\", \"!\", \" little\", \" Lily\", \" Tom\", \"!\\\"\", \" Max\", \" tree\"], [\" cat\", \" a\", \" bird\", \" little\", \" I\", \"\\n\", \" dog\", \" but\", \" frog\", \" sw\"], [\" are\", \" I\", \" was\", \" do\", \" fast\", \" big\", \" did\", \" to\", \" he\", \" old\"], [\" you\", \" we\", \" they\", \" the\", \" Lily\", \" your\", \" I\", \" Tim\", \" friends\", \" those\"], [\"?\\\"\", \" today\", \"?\", \" and\", \".\", \",\", \" doing\", \" going\", \" up\", \"?\\\".\"], [\"?\\\"\", \" this\", \" today\", \"?\", \" here\", \" a\", \" it\", \" these\", \".\", \" in\"], [\"?\\\"\", \"?\", \" great\", \" so\", \" job\", \" puzzle\", \" task\", \" very\", \".\", \" amazing\"], [\"\\ufffd\", \" You\", \" I\", \" It\", \" We\", \" Can\", \"\\n\", \" This\", \" Do\", \" Are\"], [\"'m\", \" am\", \" want\", \" like\", \" know\", \" have\", \" love\", \" can\", \" just\", \" hope\"], [\" a\", \" so\", \" very\", \" trying\", \" going\", \" an\", \" looking\", \" just\", \" making\", \" playing\"], [\" good\", \" hungry\", \" enjoying\", \" a\", \" tired\", \" proud\", \" happy\", \" excited\", \" busy\", \" glad\"], [\" the\", \" it\", \" this\", \" my\", \" a\", \" your\", \" playing\", \" some\", \" these\", \" myself\"], [\" meal\", \" food\", \" day\", \" ice\", \" sandwich\", \" delicious\", \" new\", \" dance\", \" cake\", \" time\"]], \"correctTokenRank\": [1718, 0, 675, 0, 0, 6, 1, 1, 2, 0, 23, 2, 5, 10036], \"correctTokenLogProb\": [-13.814955711364746, -1.1883898973464966, -8.445571899414062, -0.9917515516281128, -0.03712337464094162, -5.11631441116333, -2.0767040252685547, -2.737755060195923, -2.4600236415863037, -1.3091977834701538, -4.860557556152344, -3.0507826805114746, -3.9217042922973633, -17.039506912231445]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x2669f4425a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n",
    "\n",
    "# Let's make a longer prompt and see the log probabilities of the tokens\n",
    "example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 175.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-4d3b0b36-cc30\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-4d3b0b36-cc30\",\n",
       "      TokenLogProbs,\n",
       "      {\"prompt\": [\"<|endoftext|>\", \"Once\", \" upon\", \" a\", \" time\", \",\", \" there\", \" were\", \" two\", \" best\", \" friends\", \" -\", \" Jane\", \" loved\", \" to\", \" slide\", \" down\", \" the\", \" mountain\", \".\", \" Every\", \" day\", \",\", \" they\", \" would\", \" go\", \" to\", \" the\", \" lake\", \" to\", \" play\", \" on\", \" the\", \" slide\", \" in\", \" the\", \" cool\", \" water\", \".\", \" One\", \" day\", \",\", \" Jane\", \" told\", \" the\", \" slide\", \",\", \" but\", \" her\", \" little\", \" brother\", \" was\", \" mis\", \"beh\", \"aving\", \".\", \" He\", \" started\", \" screaming\", \" and\", \" running\", \" around\", \" in\", \" circles\", \".\", \" Jane\", \" got\", \" mad\", \" as\", \" she\", \" loved\", \" this\", \" way\", \".\", \" Soon\", \" she\", \" got\", \" very\", \" angry\", \" and\", \" started\", \" to\", \" shout\", \",\", \" \\\"\", \"why\", \" are\", \" you\", \" screaming\", \"?\\\"\", \" Tim\", \" shouted\", \".\", \" He\", \" shook\", \" his\", \" fists\", \" at\", \" Jane\", \" and\", \" said\", \",\", \" \\\"\", \"I\", \" didn\", \"'t\", \" know\", \" it\", \" was\", \" actually\", \" angry\", \".\", \" You\", \" could\", \" have\", \" hurt\", \" me\", \"!'\", \" Tim\", \" was\", \" really\", \" unhappy\", \"\\\".\", \" Jane\", \" felt\", \" bad\", \" for\", \" being\", \" very\", \" naughty\", \" and\", \" she\", \" knew\", \" he\", \" was\", \" wrong\", \".\", \" They\", \" took\", \" off\", \" the\", \" slide\", \" and\", \" told\", \" her\", \" that\", \" it\", \" was\", \" a\", \" bad\", \" idea\", \".\", \" They\", \" said\", \",\", \" '\", \"Let\", \"'s\", \" go\", \" down\", \" the\", \" slide\", \" together\", \" this\", \" time\", \"!\", \"'.\", \" Jane\", \" was\", \" still\", \" terrified\", \" and\", \" asked\", \" if\", \" she\", \" would\", \" forgive\", \" him\", \".\", \" Luckily\", \" they\", \" decided\", \" to\", \" talk\", \" just\", \" before\", \" her\", \" dinner\", \".\", \"\\n\", \"\\n\", \"After\", \" they\", \" looked\", \" for\", \" a\", \" while\", \",\", \" they\", \" reached\", \" a\", \" short\", \" shop\", \" and\", \" Jane\"], \"topKLogProbs\": [[-0.020238211378455162, -6.104501247406006, -7.070319652557373, -7.073489665985107, -7.178884983062744, -7.3896870613098145, -7.5253214836120605, -7.5885796546936035, -7.763060092926025, -8.22431468963623], [-0.37248945236206055, -1.82753324508667, -4.306142330169678, -4.838803768157959, -4.989407062530518, -5.111739635467529, -5.187070369720459, -5.250600337982178, -5.662858486175537, -5.694154262542725], [-0.005904730875045061, -5.495639324188232, -7.522155284881592, -8.207714080810547, -8.449647903442383, -8.90707778930664, -9.541230201721191, -9.691882133483887, -10.111766815185547, -10.492292404174805], [-0.011737806722521782, -6.031057357788086, -7.209388732910156, -7.243846893310547, -7.747932434082031, -7.977019309997559, -8.32171630859375, -8.357276916503906, -8.50236701965332, -8.701491355895996], [-0.18781840801239014, -1.8141649961471558, -5.624242782592773, -6.579643249511719, -7.82225227355957, -8.38668155670166, -8.499088287353516, -8.578033447265625, -8.82379150390625, -8.960553169250488], [-0.10250551998615265, -3.4027316570281982, -3.9464728832244873, -5.159369468688965, -5.411177635192871, -6.11348819732666, -6.131925582885742, -6.200320243835449, -6.424910545349121, -7.007170677185059], [-0.13827235996723175, -2.5443296432495117, -3.050604820251465, -7.775616645812988, -8.049700736999512, -8.075814247131348, -8.107099533081055, -8.183045387268066, -8.868167877197266, -8.878030776977539], [-0.18424437940120697, -2.888298273086548, -3.2415831089019775, -4.85001277923584, -5.08143424987793, -5.670647621154785, -5.690467834472656, -5.727752685546875, -5.860248565673828, -6.2434234619140625], [-0.7651837468147278, -1.3947784900665283, -3.268632173538208, -3.4276859760284424, -3.8666412830352783, -4.189197063446045, -4.214700222015381, -4.284421443939209, -4.694678783416748, -4.7293219566345215], [-0.0043445490300655365, -7.548476696014404, -7.750949382781982, -8.200202941894531, -8.302803039550781, -8.85624885559082, -8.867937088012695, -8.9425048828125, -9.071282386779785, -9.159299850463867], [-1.2183597087860107, -1.3717563152313232, -1.9700095653533936, -2.170811414718628, -2.268112897872925, -3.4880740642547607, -3.7196662425994873, -4.892745018005371, -5.273280143737793, -5.728493690490723], [-1.1400445699691772, -2.3614821434020996, -3.5436530113220215, -3.6852355003356934, -3.8010764122009277, -3.8200926780700684, -3.8606314659118652, -3.862252712249756, -4.210378170013428, -4.34863805770874], [-0.046382829546928406, -3.8503971099853516, -4.655033111572266, -5.471279144287109, -6.045068740844727, -6.643100738525391, -7.216161727905273, -7.268213272094727, -7.436680793762207, -8.064847946166992], [-0.4294908046722412, -3.007772207260132, -4.29608154296875, -4.536493301391602, -4.621002197265625, -4.63136100769043, -5.0748291015625, -5.1248674392700195, -5.276607513427734, -5.289181709289551], [-1.267237901687622, -2.239600419998169, -2.6660683155059814, -3.734790086746216, -3.7985317707061768, -3.890429735183716, -3.936551332473755, -4.121747016906738, -4.222170829772949, -4.3266401290893555], [-0.827423095703125, -1.4784069061279297, -2.774852752685547, -2.816286087036133, -2.921825408935547, -3.1048946380615234, -3.2304916381835938, -4.335601806640625, -4.401561737060547, -4.522762298583984], [-0.5296363830566406, -2.1483535766601562, -2.6806201934814453, -2.824411392211914, -3.4865684509277344, -3.891866683959961, -3.8977909088134766, -4.409460067749023, -4.8022613525390625, -4.9219970703125], [-1.5386178493499756, -1.6301190853118896, -1.8613622188568115, -2.4013516902923584, -3.097411870956421, -3.2927472591400146, -3.423705816268921, -4.201465606689453, -4.371959686279297, -4.76740837097168], [-0.4805505871772766, -2.835927724838257, -3.0575616359710693, -3.2668988704681396, -3.367522954940796, -3.397939443588257, -3.423173666000366, -3.4884488582611084, -4.196626663208008, -4.197614669799805], [-1.37201988697052, -1.7435275316238403, -1.756980061531067, -2.090542793273926, -2.5021371841430664, -3.5597009658813477, -3.7511796951293945, -4.015480995178223, -4.153456687927246, -4.271496772766113], [-0.15148471295833588, -2.8733437061309814, -4.0488176345825195, -4.069573402404785, -4.864733695983887, -5.084952354431152, -5.119769096374512, -5.280278205871582, -5.71236515045166, -5.89694881439209], [-0.9233695268630981, -1.1908923387527466, -1.5102664232254028, -3.920445442199707, -4.037175178527832, -4.9755144119262695, -5.099892616271973, -5.440152168273926, -5.452223777770996, -5.463860511779785], [-0.7494935989379883, -1.3845720291137695, -2.0764951705932617, -2.525486946105957, -4.521588325500488, -4.752789497375488, -4.833657264709473, -5.824348449707031, -5.842920303344727, -5.897408485412598], [-0.14666730165481567, -3.433397054672241, -4.957773208618164, -5.014980316162109, -5.044984817504883, -5.305567741394043, -5.362957000732422, -5.554385185241699, -5.596099853515625, -5.74936580657959], [-0.9950123429298401, -2.1052589416503906, -2.1433238983154297, -2.7583351135253906, -3.5803356170654297, -3.614778518676758, -3.7291927337646484, -3.9947891235351562, -4.08424186706543, -4.439889907836914], [-0.7579677700996399, -1.8210227489471436, -2.545452833175659, -3.0411460399627686, -3.060589551925659, -3.145134687423706, -3.9103667736053467, -4.016976356506348, -4.081603050231934, -4.20540714263916], [-0.059422604739665985, -4.324078559875488, -4.349514961242676, -5.327044486999512, -5.610688209533691, -6.06333065032959, -6.1619977951049805, -6.372628211975098, -6.528944969177246, -6.606451988220215], [-1.1781703233718872, -1.869914174079895, -2.151919364929199, -2.735926628112793, -3.2039289474487305, -3.488163948059082, -3.4911584854125977, -3.600955009460449, -3.744204521179199, -3.961153984069824], [-0.528644323348999, -1.5202195644378662, -2.8960301876068115, -3.1373727321624756, -3.7162110805511475, -4.035453796386719, -5.087131500244141, -5.243511199951172, -5.407218933105469, -5.606792449951172], [-0.9817149639129639, -1.6613528728485107, -3.3168704509735107, -3.465365171432495, -3.539217710494995, -3.821802854537964, -3.822138547897339, -4.085616111755371, -4.088997840881348, -4.134869575500488], [-1.072100281715393, -1.4697214365005493, -1.7359129190444946, -2.1976780891418457, -3.477238178253174, -3.949768543243408, -4.073173999786377, -4.470848560333252, -4.751022815704346, -4.936123371124268], [-0.1833234429359436, -3.4601082801818848, -3.6122021675109863, -3.6443257331848145, -4.283565998077393, -4.333250522613525, -4.708237171173096, -5.0384297370910645, -5.433788776397705, -6.175266742706299], [-0.7464687824249268, -1.903306245803833, -3.061846971511841, -3.3349735736846924, -3.5096371173858643, -3.586097002029419, -3.6129162311553955, -4.002232551574707, -4.0648088455200195, -4.366625785827637], [-0.4325031042098999, -1.6923679113388062, -2.2396302223205566, -4.045820713043213, -4.650496006011963, -5.970297336578369, -6.115803241729736, -6.1217942237854, -6.1824421882629395, -6.612181186676025], [-0.16442151367664337, -2.2681851387023926, -4.246273517608643, -5.252954959869385, -5.377441883087158, -5.81731653213501, -6.571264743804932, -6.6269707679748535, -6.679019451141357, -7.009674549102783], [-1.5852859020233154, -1.877821683883667, -2.2261245250701904, -2.6173694133758545, -2.9599616527557373, -3.253483533859253, -3.9056899547576904, -3.94685435295105, -4.019762992858887, -4.095231056213379], [-0.5157206058502197, -2.7028086185455322, -3.4863131046295166, -3.7164270877838135, -3.80574631690979, -4.141271591186523, -4.280143737792969, -4.321067810058594, -4.3594512939453125, -4.390605926513672], [-0.09311053901910782, -3.3742213249206543, -3.688819408416748, -5.541745662689209, -5.787587642669678, -6.187093257904053, -6.565272808074951, -6.769006252288818, -6.875460147857666, -7.0448079109191895], [-0.41577181220054626, -2.0021917819976807, -2.9140207767486572, -3.3033335208892822, -3.844270944595337, -3.9157469272613525, -4.0399956703186035, -4.175783634185791, -5.690999507904053, -5.701333522796631], [-0.029738498851656914, -4.732142448425293, -5.694113731384277, -6.057866096496582, -6.405646324157715, -6.571381568908691, -6.6337480545043945, -6.683779716491699, -7.143052101135254, -7.1666154861450195], [-0.08854794502258301, -4.088316917419434, -4.199212074279785, -4.53781795501709, -4.682843208312988, -4.925013542175293, -5.185938835144043, -5.7510881423950195, -6.123806953430176, -6.3156633377075195], [-1.4284672737121582, -1.817314624786377, -1.9011921882629395, -2.3420796394348145, -2.4581379890441895, -2.9589791297912598, -3.017122745513916, -3.3456616401672363, -3.491417407989502, -3.5151352882385254], [-2.175748109817505, -2.2433807849884033, -2.3470852375030518, -2.425555467605591, -2.573561906814575, -2.606156587600708, -2.6148197650909424, -2.7999088764190674, -3.0281383991241455, -3.3104069232940674], [-0.1764245480298996, -2.675489902496338, -4.045647144317627, -4.198458194732666, -4.386648654937744, -4.78117036819458, -5.4847283363342285, -5.511328220367432, -5.586611270904541, -6.047491550445557], [-1.210654377937317, -2.0851011276245117, -2.971245765686035, -3.1464033126831055, -3.395197868347168, -3.4453248977661133, -3.582045555114746, -3.7614450454711914, -3.9009923934936523, -3.939938545227051], [-1.0439530611038208, -1.4239312410354614, -2.566394805908203, -2.7193069458007812, -3.4991588592529297, -3.5540008544921875, -3.5648860931396484, -3.8276443481445312, -3.885578155517578, -4.849061965942383], [-0.38029366731643677, -1.3512980937957764, -3.5728671550750732, -4.811892509460449, -5.690279960632324, -6.330548286437988, -6.3392839431762695, -6.61122989654541, -6.8984270095825195, -6.986268043518066], [-0.775671660900116, -2.1348140239715576, -2.623224973678589, -3.060009717941284, -3.1470859050750732, -3.3148200511932373, -3.5166728496551514, -3.79034686088562, -3.9316508769989014, -4.4451470375061035], [-1.3079860210418701, -2.1252143383026123, -2.865462064743042, -3.1746585369110107, -3.7456042766571045, -3.7762038707733154, -3.7996089458465576, -4.086813926696777, -4.194106101989746, -4.200794219970703], [-0.1891482025384903, -3.6000616550445557, -3.8605806827545166, -4.3265061378479, -4.5513386726379395, -4.87769079208374, -5.2191948890686035, -5.301564693450928, -5.395754337310791, -5.676629543304443], [-1.8769748210906982, -1.9730327129364014, -2.2411773204803467, -2.3080432415008545, -2.986302137374878, -3.129379987716675, -3.3421695232391357, -3.517479658126831, -3.6455771923065186, -3.7032382488250732], [-1.771186113357544, -2.3415043354034424, -2.448188066482544, -2.5531532764434814, -2.6865265369415283, -3.129328966140747, -3.4031498432159424, -3.7424309253692627, -3.8132355213165283, -3.8195488452911377], [-0.6766725778579712, -0.7585302591323853, -5.1699090003967285, -5.741121768951416, -6.811995029449463, -6.815711498260498, -6.818848133087158, -7.093101978302002, -7.378523349761963, -7.556721210479736], [-0.007602449040859938, -5.710246562957764, -6.812957286834717, -7.443538188934326, -8.582242965698242, -8.709945678710938, -8.783024787902832, -9.210765838623047, -9.243983268737793, -9.395062446594238], [-0.32608187198638916, -1.4994827508926392, -4.443559169769287, -4.790050029754639, -5.643664836883545, -5.6719069480896, -5.758021831512451, -5.787423610687256, -5.888026714324951, -6.100186824798584], [-0.6246393918991089, -1.7046946287155151, -2.2835140228271484, -2.790994644165039, -3.170370101928711, -3.9354801177978516, -4.436201095581055, -4.7094879150390625, -5.130781173706055, -5.449991226196289], [-1.3965531587600708, -1.4851628541946411, -2.5657386779785156, -3.187946319580078, -3.2294921875, -3.2841854095458984, -3.423257827758789, -3.8220386505126953, -3.8345603942871094, -4.164375305175781], [-0.15049207210540771, -4.066328525543213, -4.271965503692627, -4.639317035675049, -4.7279744148254395, -4.812057971954346, -4.916422367095947, -5.153570652008057, -5.160406589508057, -5.181887149810791], [-0.39497438073158264, -2.5516936779022217, -2.8444125652313232, -3.277266263961792, -3.9057281017303467, -4.318617343902588, -4.430948734283447, -4.494259357452393, -4.617554187774658, -4.734558582305908], [-2.2036781311035156, -2.376148223876953, -2.4366092681884766, -2.631153106689453, -2.7052135467529297, -3.0791549682617188, -3.1161880493164062, -3.1281871795654297, -3.1504077911376953, -3.2935028076171875], [-0.3752288520336151, -1.992391586303711, -3.627969741821289, -3.9554290771484375, -4.294740676879883, -4.52971076965332, -4.610136032104492, -4.686351776123047, -4.742298126220703, -5.033840179443359], [-1.0483529567718506, -1.472137212753296, -1.7821366786956787, -2.5565145015716553, -3.866891622543335, -3.997730016708374, -4.465038299560547, -4.573541641235352, -4.673824310302734, -5.064544677734375], [-0.5688799619674683, -1.2637213468551636, -3.395334243774414, -4.108844757080078, -4.231634140014648, -4.52043342590332, -4.821210861206055, -5.066045761108398, -5.547607421875, -5.654537200927734], [-0.5999304056167603, -1.4309431314468384, -2.7816033363342285, -3.2699437141418457, -4.043135166168213, -4.04424524307251, -4.982815265655518, -5.146982669830322, -5.255581378936768, -5.369682788848877], [-0.34991395473480225, -2.2062087059020996, -2.677581310272217, -3.5515799522399902, -3.657130718231201, -4.5995192527771, -4.646825313568115, -4.752604961395264, -5.740617275238037, -5.794101238250732], [-1.0998870134353638, -2.2631959915161133, -2.8207101821899414, -2.8886003494262695, -3.1923418045043945, -3.2305612564086914, -3.342156410217285, -3.52681827545166, -3.5358152389526367, -3.652277946472168], [-1.6460875272750854, -1.6904009580612183, -1.8247183561325073, -2.1894760131835938, -2.2925453186035156, -2.3999290466308594, -3.4807281494140625, -3.743175506591797, -4.107046127319336, -4.262401580810547], [-0.18475061655044556, -2.588261604309082, -3.42800235748291, -4.226658821105957, -4.365584373474121, -4.428530693054199, -5.124619483947754, -5.538022041320801, -5.874403953552246, -6.487179756164551], [-0.2266160398721695, -2.782270669937134, -3.449342966079712, -3.8266870975494385, -3.8512423038482666, -4.596162796020508, -4.923765182495117, -5.367731094360352, -5.451740264892578, -5.584573745727539], [-2.4389917850494385, -2.527740716934204, -2.8536531925201416, -2.9164927005767822, -3.004040002822876, -3.155988931655884, -3.211559534072876, -3.2638094425201416, -3.399587869644165, -3.557049036026001], [-1.1976648569107056, -1.7421728372573853, -2.3962903022766113, -2.4455933570861816, -2.5023961067199707, -2.8584446907043457, -3.325014591217041, -3.7590413093566895, -3.8202099800109863, -4.295422077178955], [-1.305125117301941, -2.551070213317871, -2.5881032943725586, -2.8359670639038086, -3.069594383239746, -3.138308525085449, -3.3083906173706055, -3.6705522537231445, -3.673130989074707, -3.74906063079834], [-0.8926252722740173, -1.374091625213623, -1.6228766441345215, -2.3953452110290527, -4.42538595199585, -5.4019694328308105, -5.515866756439209, -5.83021879196167, -5.847377300262451, -6.080159664154053], [-0.9993869662284851, -1.2631428241729736, -2.219853639602661, -3.279517412185669, -3.451810121536255, -3.6694538593292236, -3.7486469745635986, -4.186633110046387, -4.2040205001831055, -4.387454032897949], [-0.5037981271743774, -2.1110920906066895, -2.393860340118408, -3.2320656776428223, -3.785635471343994, -3.793510913848877, -3.8973488807678223, -4.095907688140869, -4.398313999176025, -4.6469597816467285], [-0.807465136051178, -2.736534595489502, -3.0262646675109863, -3.3569493293762207, -3.3584084510803223, -3.526754856109619, -3.6049466133117676, -3.681379795074463, -3.725353717803955, -3.7489724159240723], [-1.7888532876968384, -2.09171724319458, -2.3512463569641113, -2.778934955596924, -2.801943302154541, -2.8612427711486816, -3.400331974029541, -3.4059510231018066, -3.499603748321533, -3.5708889961242676], [-1.3395881652832031, -1.9257965087890625, -1.9626655578613281, -2.9614505767822266, -3.331645965576172, -3.424274444580078, -3.4748363494873047, -3.5803966522216797, -3.956155776977539, -4.028289794921875], [-0.37545686960220337, -1.9512109756469727, -3.249325752258301, -3.4426984786987305, -3.529831886291504, -4.165705680847168, -4.36112117767334, -4.751530647277832, -4.758946418762207, -5.39060115814209], [-1.3195695877075195, -2.0645132064819336, -2.083096504211426, -3.131892204284668, -3.416928291320801, -3.459805488586426, -3.7904558181762695, -3.80277156829834, -3.88594913482666, -3.8971452713012695], [-0.805349588394165, -1.8746225833892822, -2.381784677505493, -2.560211420059204, -3.4986326694488525, -3.7464144229888916, -3.9455454349517822, -4.221532821655273, -4.288677215576172, -4.681192398071289], [-1.2847580909729004, -1.3430066108703613, -2.049063205718994, -2.4280056953430176, -3.576385974884033, -3.8503384590148926, -4.084017276763916, -4.372122287750244, -4.389057636260986, -4.590761661529541], [-1.0307602882385254, -1.1297039985656738, -2.592939853668213, -2.8785157203674316, -3.823185443878174, -3.9029221534729004, -4.384556293487549, -4.41686487197876, -4.42593240737915, -4.481396198272705], [-0.1928037703037262, -2.827117443084717, -3.9169116020202637, -4.0515265464782715, -4.1827006340026855, -5.1137824058532715, -5.17108678817749, -5.4894022941589355, -5.526366710662842, -5.858739376068115], [-1.4383630752563477, -1.987105369567871, -2.1790151596069336, -2.6880178451538086, -2.827305793762207, -3.129361152648926, -3.553277015686035, -3.601734161376953, -3.675835609436035, -4.026602745056152], [-0.5717241764068604, -1.7461912631988525, -2.855470895767212, -2.9927446842193604, -3.854828119277954, -3.936167001724243, -4.087726593017578, -4.37278938293457, -4.761207580566406, -5.096126556396484], [-0.0025132279843091965, -7.155187129974365, -7.775943279266357, -7.8922553062438965, -8.479016304016113, -9.097594261169434, -9.536784172058105, -9.67116641998291, -9.72652530670166, -9.767868995666504], [-1.1006380319595337, -1.245726227760315, -2.2896523475646973, -2.3551621437072754, -2.8107895851135254, -3.866030216217041, -3.9457345008850098, -4.5799946784973145, -4.90073823928833, -5.11074686050415], [-1.2356358766555786, -1.4605408906936646, -1.8566418886184692, -1.9785386323928833, -3.3521347045898438, -3.373685836791992, -3.811105728149414, -3.8521862030029297, -4.634494781494141, -4.725879669189453], [-1.2167600393295288, -2.1606059074401855, -2.316831111907959, -2.380317211151123, -2.4597373008728027, -2.7337546348571777, -3.2485709190368652, -3.7128634452819824, -3.7647433280944824, -3.9803366661071777], [-1.3513261079788208, -1.8817979097366333, -2.0255813598632812, -2.5454940795898438, -2.9420738220214844, -3.194355010986328, -3.433664321899414, -3.7754459381103516, -4.13099479675293, -4.15485954284668], [-0.7252607345581055, -2.083918571472168, -2.442488670349121, -2.973660469055176, -3.45497989654541, -3.625237464904785, -3.860562324523926, -3.8718366622924805, -4.345410346984863, -4.637412071228027], [-0.8758924007415771, -1.882657766342163, -2.249837636947632, -2.659871816635132, -2.8332135677337646, -3.0546834468841553, -3.4262006282806396, -4.236154556274414, -4.4314727783203125, -4.647922515869141], [-0.7845824360847473, -2.241312265396118, -2.9985029697418213, -3.407654047012329, -3.4767115116119385, -3.5522329807281494, -3.7062628269195557, -3.730692148208618, -3.9585306644439697, -3.9967539310455322], [-0.1665811538696289, -2.958071708679199, -3.309727668762207, -3.9010114669799805, -4.337708473205566, -5.050869941711426, -5.2099199295043945, -6.136641502380371, -6.483738899230957, -6.9081315994262695], [-0.10311776399612427, -3.1266391277313232, -3.86579966545105, -5.41165828704834, -5.4510393142700195, -5.530732154846191, -6.116772651672363, -6.326384544372559, -6.3678178787231445, -6.563981056213379], [-1.0154649019241333, -1.163540005683899, -2.216564178466797, -3.2995986938476562, -3.673257827758789, -4.099205017089844, -4.137449264526367, -4.184976577758789, -4.21068000793457, -4.432697296142578], [-0.650001049041748, -1.0131678581237793, -2.671821117401123, -3.8244967460632324, -5.8572611808776855, -5.943152904510498, -6.648253917694092, -6.758300304412842, -6.929497241973877, -7.099447727203369], [-0.5162434577941895, -2.040234088897705, -2.221296787261963, -3.1270413398742676, -3.8469090461730957, -4.027821063995361, -4.309410572052002, -4.546356678009033, -4.784336566925049, -4.891371250152588], [-0.5815250873565674, -2.211329698562622, -2.5259411334991455, -3.43572735786438, -3.898005723953247, -3.9902756214141846, -4.116990089416504, -4.409571647644043, -4.4893083572387695, -4.591055870056152], [-0.49372515082359314, -1.7201999425888062, -2.8716299533843994, -3.428175210952759, -3.5642454624176025, -4.2735772132873535, -4.505112171173096, -5.0559163093566895, -5.105854511260986, -5.349567890167236], [-0.01076321117579937, -4.972394943237305, -6.639337539672852, -7.098371505737305, -7.37061882019043, -8.112493515014648, -9.287555694580078, -9.837839126586914, -9.946523666381836, -9.986190795898438], [-1.2943432331085205, -1.9407036304473877, -2.2585957050323486, -2.493626832962036, -3.0325729846954346, -3.360978364944458, -3.45854115486145, -3.5446856021881104, -3.8113081455230713, -4.140630722045898], [-0.7662520408630371, -1.4759364128112793, -2.587777614593506, -2.641385555267334, -3.3558859825134277, -3.968104839324951, -4.021180629730225, -4.27351713180542, -4.9065470695495605, -5.1510233879089355], [-0.0034656007774174213, -5.720829010009766, -10.469575881958008, -10.639314651489258, -11.621379852294922, -11.816530227661133, -12.136587142944336, -12.18994426727295, -12.288420677185059, -12.503440856933594], [-1.4505467414855957, -1.9791722297668457, -2.6037964820861816, -2.68467378616333, -3.1022400856018066, -3.2600560188293457, -3.5713047981262207, -3.756194591522217, -3.97385835647583, -4.011244297027588], [-1.6599316596984863, -1.9460759162902832, -2.0650181770324707, -2.315575122833252, -2.5454564094543457, -2.712254047393799, -3.252941608428955, -3.331669330596924, -3.369194507598877, -3.707094669342041], [-0.307251513004303, -1.91630220413208, -3.3224949836730957, -3.973494052886963, -4.4787983894348145, -5.443312168121338, -5.584339618682861, -5.588345050811768, -5.596601963043213, -5.6997246742248535], [-1.705119252204895, -2.3475961685180664, -2.54171085357666, -2.8227357864379883, -2.8725500106811523, -2.9458398818969727, -3.040116310119629, -3.172116279602051, -3.461602210998535, -3.509476661682129], [-1.0050461292266846, -2.5312187671661377, -3.027545213699341, -3.2192203998565674, -3.333991289138794, -4.004115104675293, -4.106348991394043, -4.108248710632324, -4.12748908996582, -4.159778594970703], [-1.2542147636413574, -1.4446310997009277, -1.6536154747009277, -2.6913504600524902, -2.818429470062256, -2.8936057090759277, -3.5999655723571777, -4.229978084564209, -4.350768566131592, -4.361129283905029], [-0.4806784391403198, -2.786977767944336, -2.8322792053222656, -2.8687591552734375, -3.7138614654541016, -3.794748306274414, -3.878936767578125, -4.472809791564941, -4.572656631469727, -4.623302459716797], [-1.838699460029602, -2.0905609130859375, -2.321969985961914, -2.5681419372558594, -2.7500152587890625, -2.9788665771484375, -3.2269840240478516, -3.2454471588134766, -3.4104576110839844, -3.499378204345703], [-0.26797130703926086, -2.8416731357574463, -3.5420401096343994, -4.109888553619385, -4.244949817657471, -4.36307954788208, -4.880329608917236, -4.954473972320557, -4.972486972808838, -5.004364490509033], [-0.7595131397247314, -1.5907185077667236, -1.8624851703643799, -3.7090561389923096, -4.0348100662231445, -4.223446846008301, -4.455428123474121, -4.804446220397949, -5.182011604309082, -5.58449649810791], [-0.5377371907234192, -1.5198709964752197, -2.5316965579986572, -3.6845648288726807, -4.190880298614502, -4.228308200836182, -5.121912479400635, -5.533329486846924, -5.533470630645752, -5.5431599617004395], [-0.5627681016921997, -2.4174680709838867, -2.6713876724243164, -3.3692827224731445, -3.404810905456543, -3.416630744934082, -3.6730051040649414, -3.8041906356811523, -4.089602470397949, -4.565770149230957], [-1.5590254068374634, -2.131470203399658, -2.1719937324523926, -2.592224597930908, -2.6446499824523926, -2.7086243629455566, -3.3430771827697754, -3.4096531867980957, -3.4421582221984863, -3.548344135284424], [-0.9734164476394653, -1.7613040208816528, -3.4324750900268555, -3.4485082626342773, -3.472701072692871, -3.600430488586426, -3.803072929382324, -3.9716062545776367, -4.054503440856934, -4.1891279220581055], [-1.01353120803833, -1.5888104438781738, -2.447542667388916, -2.821737766265869, -2.965567111968994, -3.1884236335754395, -3.5660557746887207, -3.7098889350891113, -4.094946384429932, -4.161257266998291], [-0.9092857241630554, -1.6611683368682861, -1.937403917312622, -2.9795982837677, -3.27470326423645, -3.384732484817505, -3.683438539505005, -3.857165575027466, -4.004504203796387, -4.610329627990723], [-0.4858306050300598, -2.1667540073394775, -2.321686029434204, -2.910715341567993, -3.2155706882476807, -4.0804009437561035, -4.12856912612915, -4.981062412261963, -5.244804859161377, -5.292362689971924], [-0.8649066686630249, -1.8088382482528687, -2.459251880645752, -2.7335381507873535, -2.784536838531494, -3.1292996406555176, -3.149324893951416, -4.076778888702393, -4.2481865882873535, -4.27361536026001], [-1.3653086423873901, -1.530135989189148, -2.725992202758789, -3.062631607055664, -3.444948196411133, -3.4992218017578125, -3.650867462158203, -3.766328811645508, -3.814340591430664, -4.179832458496094], [-1.065718650817871, -1.794245719909668, -2.233445167541504, -2.549929618835449, -2.694535255432129, -2.695868492126465, -3.551255226135254, -3.7997827529907227, -3.863184928894043, -4.136298179626465], [-0.6305254101753235, -1.2790391445159912, -2.7359063625335693, -3.279844045639038, -3.7902867794036865, -3.8638741970062256, -3.8786637783050537, -4.662586212158203, -6.253705978393555, -6.331354141235352], [-1.7180795669555664, -2.1719160079956055, -2.429326057434082, -2.5077390670776367, -2.536759376525879, -2.58536434173584, -2.7612600326538086, -3.043370246887207, -3.4463319778442383, -3.632626533508301], [-0.22969335317611694, -2.9345102310180664, -3.42189884185791, -3.6916093826293945, -4.088921546936035, -4.159096717834473, -5.115723609924316, -5.163418769836426, -5.170514106750488, -5.843234062194824], [-1.969748616218567, -2.08925724029541, -2.255801200866699, -2.800173759460449, -2.87686824798584, -2.9046430587768555, -2.9088735580444336, -3.0389089584350586, -3.059403419494629, -3.56430721282959], [-0.577147364616394, -1.5107430219650269, -1.8834389448165894, -3.326584815979004, -5.217999458312988, -5.848095893859863, -6.027379035949707, -6.287114143371582, -6.345572471618652, -6.429600715637207], [-1.779992938041687, -1.8192557096481323, -2.3040027618408203, -2.7312183380126953, -2.747344970703125, -3.00982666015625, -3.3341331481933594, -4.203104019165039, -4.3721466064453125, -4.404680252075195], [-1.8677313327789307, -2.2339842319488525, -2.5011446475982666, -2.7412779331207275, -2.761505365371704, -2.9155218601226807, -3.3598082065582275, -3.3855135440826416, -3.6712515354156494, -3.749696969985962], [-0.43293094635009766, -2.0376768112182617, -2.2981691360473633, -3.3816118240356445, -4.424332618713379, -4.605330467224121, -4.7180891036987305, -4.802060127258301, -4.871842384338379, -5.272030830383301], [-0.5943465232849121, -1.518571376800537, -2.874457836151123, -3.3443617820739746, -3.8612380027770996, -4.124661922454834, -4.290404796600342, -4.3174052238464355, -4.517932415008545, -4.622800350189209], [-0.9947794079780579, -1.589008092880249, -1.6248929500579834, -2.880798101425171, -3.705331563949585, -3.752246618270874, -4.4861297607421875, -4.576864242553711, -4.880878448486328, -4.895586013793945], [-0.06083216518163681, -3.3993217945098877, -4.715788841247559, -5.389491081237793, -6.013033866882324, -6.565497398376465, -6.631941795349121, -7.103274345397949, -7.1794023513793945, -7.711236000061035], [-1.3578611612319946, -1.4186197519302368, -1.9502722024917603, -2.1390461921691895, -2.7277302742004395, -3.1806836128234863, -3.299408435821533, -3.8062214851379395, -4.42699670791626, -4.554771900177002], [-1.297350525856018, -1.4953314065933228, -2.302635669708252, -2.804230213165283, -2.8152356147766113, -3.7651734352111816, -3.8862080574035645, -3.911102771759033, -4.1764912605285645, -4.312668323516846], [-1.2673907279968262, -1.462216854095459, -2.4686636924743652, -2.6411566734313965, -2.848435878753662, -3.0029654502868652, -3.044858455657959, -3.107125759124756, -3.1549105644226074, -4.4353251457214355], [-0.597136378288269, -1.4432553052902222, -3.129603385925293, -3.4347238540649414, -3.5592851638793945, -3.705916404724121, -3.984145164489746, -4.77431583404541, -4.788580894470215, -5.469836235046387], [-0.3132166862487793, -3.4029250144958496, -3.5119776725769043, -3.9628653526306152, -4.56127405166626, -4.5871663093566895, -4.9213385581970215, -5.071048259735107, -5.368902683258057, -5.483635425567627], [-0.16219192743301392, -3.2723488807678223, -3.2874302864074707, -4.830708026885986, -5.1251702308654785, -5.151421070098877, -5.238476276397705, -5.382191181182861, -5.431652545928955, -5.9323296546936035], [-2.302694082260132, -2.6103665828704834, -2.860910177230835, -3.052213430404663, -3.0543229579925537, -3.1680963039398193, -3.1865556240081787, -3.34647536277771, -3.515949010848999, -3.5720536708831787], [-1.0941803455352783, -1.4140713214874268, -1.7221310138702393, -2.716262102127075, -3.036729097366333, -3.735541582107544, -3.924922227859497, -3.9671318531036377, -4.149718284606934, -4.547499656677246], [-1.862054467201233, -2.017737865447998, -2.582728862762451, -2.6326537132263184, -2.751981258392334, -2.8443522453308105, -2.9637656211853027, -3.009753704071045, -3.395608425140381, -3.408740520477295], [-1.4229860305786133, -1.5409250259399414, -1.5861406326293945, -2.3013124465942383, -3.165036201477051, -3.805605888366699, -3.907200813293457, -4.307642936706543, -4.335806846618652, -4.855049133300781], [-0.26988038420677185, -2.734498977661133, -3.0018959045410156, -3.083040237426758, -4.068096160888672, -4.484527587890625, -4.870616912841797, -5.0715484619140625, -5.4417877197265625, -5.780244827270508], [-1.1619453430175781, -1.9248046875, -2.391408920288086, -2.523496627807617, -2.5361289978027344, -2.7388439178466797, -3.0620994567871094, -3.4617366790771484, -3.787372589111328, -4.258707046508789], [-0.9529871940612793, -2.2224669456481934, -2.816455364227295, -3.002183437347412, -3.0236525535583496, -3.647325038909912, -4.018439769744873, -4.1293416023254395, -4.300622463226318, -4.3424811363220215], [-1.1244549751281738, -1.4841923713684082, -2.161716938018799, -2.4036660194396973, -2.525953769683838, -3.486380100250244, -4.25449800491333, -4.449051380157471, -4.8144402503967285, -4.819675922393799], [-0.4911348521709442, -1.2016355991363525, -3.168377161026001, -3.9969370365142822, -5.358125686645508, -5.725273132324219, -5.880764007568359, -6.19807243347168, -6.547412872314453, -6.678495407104492], [-1.6362488269805908, -1.6628811359405518, -2.1676971912384033, -2.3689873218536377, -2.6543877124786377, -3.0627377033233643, -3.1727516651153564, -3.4409687519073486, -3.5893852710723877, -3.608130693435669], [-1.3271512985229492, -2.4345998764038086, -2.74593448638916, -3.0940446853637695, -3.0940656661987305, -3.6590776443481445, -3.6714162826538086, -3.8061704635620117, -3.813309669494629, -3.9064111709594727], [-0.6717627048492432, -1.8487093448638916, -2.2663958072662354, -3.448974847793579, -3.6693994998931885, -3.6833784580230713, -3.6909658908843994, -4.009672164916992, -4.0240020751953125, -4.3811187744140625], [-0.6430174708366394, -0.8852793574333191, -3.5912559032440186, -4.922619342803955, -5.022337436676025, -5.230358600616455, -5.444847583770752, -6.757805347442627, -7.337540149688721, -7.522659778594971], [-1.0419840812683105, -2.7125353813171387, -2.8840537071228027, -3.062833309173584, -3.070950984954834, -3.2777905464172363, -3.2807669639587402, -3.440483570098877, -3.633025646209717, -3.736415386199951], [-0.03742760792374611, -3.873067617416382, -4.888526439666748, -5.242848873138428, -7.006235599517822, -7.950653553009033, -8.345550537109375, -8.351907730102539, -8.714635848999023, -8.77167797088623], [-0.9128149747848511, -2.486083984375, -3.1570186614990234, -3.2800769805908203, -3.4804954528808594, -3.5481700897216797, -3.5748558044433594, -3.6114749908447266, -3.742279052734375, -3.8815155029296875], [-1.246380090713501, -1.3982164859771729, -2.4297335147857666, -3.117902994155884, -3.4919416904449463, -3.5428431034088135, -3.636388063430786, -3.701673746109009, -3.99532151222229, -4.406538009643555], [-0.41720911860466003, -1.8363680839538574, -3.362666606903076, -3.7314867973327637, -4.353119373321533, -4.382659435272217, -4.408671855926514, -4.96278715133667, -5.239730358123779, -5.361850261688232], [-0.05869555473327637, -3.4219844341278076, -4.3400774002075195, -6.106154441833496, -6.117735862731934, -7.114609718322754, -7.247082710266113, -7.527216911315918, -7.996335029602051, -8.26030158996582], [-0.5204674005508423, -2.0104613304138184, -3.620511531829834, -4.31477689743042, -4.404056072235107, -4.458096027374268, -4.465729236602783, -4.508254528045654, -4.59436559677124, -4.612019062042236], [-0.9555792808532715, -2.2274088859558105, -2.54414701461792, -2.7337660789489746, -2.859769344329834, -3.393237590789795, -3.757791042327881, -3.7997870445251465, -3.965890407562256, -3.975503444671631], [-0.08036521822214127, -2.717076301574707, -5.894169807434082, -6.116164207458496, -6.369301795959473, -6.712855339050293, -7.217066764831543, -8.274086952209473, -8.636847496032715, -8.683073997497559], [-1.6397459506988525, -1.7083837985992432, -1.7419607639312744, -2.313957452774048, -2.331167459487915, -2.5829031467437744, -3.4200479984283447, -3.7233335971832275, -3.73543381690979, -4.713724136352539], [-0.9169183373451233, -2.058689594268799, -2.232283115386963, -2.397390842437744, -2.935547351837158, -3.328181743621826, -3.8111815452575684, -3.964848041534424, -4.4884562492370605, -4.666731357574463], [-0.9686422944068909, -1.5695600509643555, -2.496687889099121, -2.541384696960449, -2.7609357833862305, -3.0952653884887695, -3.4821062088012695, -3.599919319152832, -4.200366020202637, -4.69382381439209], [-1.149220585823059, -1.5949450731277466, -2.3174314498901367, -2.329167366027832, -2.3544092178344727, -3.664181709289551, -4.0935564041137695, -4.466561317443848, -4.643603324890137, -4.897494316101074], [-0.6430497169494629, -2.2275567054748535, -2.628479480743408, -2.79020357131958, -3.4075798988342285, -3.507967472076416, -3.7197136878967285, -3.7226815223693848, -3.8301968574523926, -4.4538044929504395], [-1.5989524126052856, -1.9931594133377075, -2.2826948165893555, -2.591925621032715, -2.842860221862793, -2.8640928268432617, -2.922205924987793, -3.210524559020996, -3.5617971420288086, -3.6096296310424805], [-0.6925819516181946, -1.7820441722869873, -2.0686442852020264, -2.458876371383667, -3.953280210494995, -4.053582191467285, -4.0836687088012695, -4.927119255065918, -4.978632926940918, -5.136792182922363], [-1.949977993965149, -2.3268260955810547, -2.6132450103759766, -2.7267704010009766, -2.7897701263427734, -3.1823291778564453, -3.238130569458008, -3.4454784393310547, -3.4726123809814453, -3.571989059448242], [-0.4362071752548218, -2.6985573768615723, -2.9594998359680176, -2.9946084022521973, -3.127800464630127, -3.5659642219543457, -3.6935086250305176, -4.277914524078369, -4.72549295425415, -4.764233112335205], [-0.8807977437973022, -1.1713365316390991, -2.457820415496826, -2.682055950164795, -3.786607265472412, -4.176517009735107, -4.238967418670654, -4.2740702629089355, -4.317763805389404, -4.804324626922607], [-0.42557230591773987, -1.9334362745285034, -2.539423942565918, -2.858757972717285, -4.21866512298584, -4.588461875915527, -4.963807106018066, -5.7992658615112305, -5.9572858810424805, -6.035651206970215], [-1.970598578453064, -2.5018067359924316, -2.7835640907287598, -3.021397113800049, -3.126844882965088, -3.4959816932678223, -3.5818848609924316, -3.7196526527404785, -3.726393222808838, -3.774139881134033], [-0.9743092060089111, -1.1930229663848877, -2.336697816848755, -2.472670793533325, -3.709876298904419, -4.356368064880371, -4.535954475402832, -4.646523475646973, -4.705121040344238, -4.717471122741699], [-0.4844643175601959, -1.860761284828186, -2.666696310043335, -2.7754151821136475, -3.544179677963257, -5.133174419403076, -5.178843975067139, -5.291854381561279, -5.6358962059021, -5.9449591636657715], [-1.2728904485702515, -2.269979953765869, -2.4536118507385254, -2.590973377227783, -2.668823719024658, -2.802072048187256, -3.0479979515075684, -3.0740599632263184, -3.5437960624694824, -3.8485302925109863], [-0.11486966907978058, -3.8833441734313965, -4.2604594230651855, -4.5905375480651855, -4.749593257904053, -5.43979024887085, -5.581664562225342, -5.715329647064209, -5.829051494598389, -5.896312236785889], [-1.640816569328308, -1.7358978986740112, -1.8116158246994019, -2.8522253036499023, -2.9938268661499023, -3.305415153503418, -3.5757246017456055, -3.5794878005981445, -3.6124868392944336, -3.718581199645996], [-0.5657970309257507, -1.8780148029327393, -2.732671022415161, -2.863408327102661, -3.6485702991485596, -4.020325660705566, -4.1807756423950195, -4.644434928894043, -5.060456275939941, -5.299527168273926], [-1.5673211812973022, -2.421973705291748, -2.4267916679382324, -3.2198424339294434, -3.35078763961792, -3.601684093475342, -3.612117290496826, -3.6275362968444824, -3.71193265914917, -3.8867831230163574], [-0.4253111183643341, -2.44913387298584, -2.8349828720092773, -3.075089454650879, -4.188569068908691, -4.594086647033691, -4.722533226013184, -4.8986616134643555, -4.9667558670043945, -5.028876304626465], [-1.6758372783660889, -2.0408427715301514, -2.1407535076141357, -2.6254146099090576, -2.9379680156707764, -2.9749629497528076, -3.488154172897339, -3.506880521774292, -3.5453803539276123, -3.5603721141815186], [-1.4375877380371094, -1.7257823944091797, -1.7774295806884766, -3.021484375, -3.181354522705078, -3.2088546752929688, -3.438131332397461, -3.529468536376953, -3.9247207641601562, -3.9711380004882812], [-1.6514089107513428, -1.8076436519622803, -1.9190900325775146, -2.5289876461029053, -2.9646432399749756, -3.546722173690796, -3.709742307662964, -3.7420079708099365, -3.8824574947357178, -4.271993637084961], [-0.4409850537776947, -2.2681658267974854, -2.6597464084625244, -3.8175909519195557, -4.458292484283447, -4.535768985748291, -4.590456485748291, -4.789159297943115, -5.0171589851379395, -5.017442226409912], [-1.168308973312378, -2.1657111644744873, -2.1684443950653076, -2.254601240158081, -2.675938367843628, -2.86177134513855, -3.5914580821990967, -3.7376277446746826, -3.7749526500701904, -4.008866310119629], [-0.6876299977302551, -1.807831048965454, -2.250864267349243, -2.993023157119751, -3.4974730014801025, -3.738630533218384, -3.895341157913208, -4.0065178871154785, -4.424510478973389, -4.597900867462158], [-1.2017478942871094, -1.7906131744384766, -2.3256168365478516, -2.608051300048828, -2.6483192443847656, -2.731342315673828, -3.1038055419921875, -3.323709487915039, -4.264421463012695, -4.268110275268555], [-0.6585180759429932, -2.0665132999420166, -2.215435266494751, -2.6983892917633057, -2.7580130100250244, -3.635948419570923, -4.444858551025391, -4.875276565551758, -4.999494552612305, -5.049600601196289], [-1.9909594058990479, -2.0389883518218994, -2.113077402114868, -2.3729116916656494, -2.8294107913970947, -2.8558733463287354, -3.0895426273345947, -3.20107102394104, -3.429453134536743, -3.457998514175415], [-0.4618510901927948, -2.6754226684570312, -2.829425811767578, -3.343942642211914, -3.4652366638183594, -3.654317855834961, -3.968534469604492, -3.982067108154297, -4.034198760986328, -4.11829948425293], [-0.1302422136068344, -3.114882230758667, -3.7313754558563232, -3.8967998027801514, -4.958727836608887, -5.3819684982299805, -5.457903861999512, -5.72702693939209, -5.8691816329956055, -6.703581809997559], [-0.8037805557250977, -2.263106346130371, -2.349656105041504, -2.5182790756225586, -2.756503105163574, -3.0544118881225586, -3.5478029251098633, -4.295523643493652, -4.297035217285156, -4.551366806030273], [-0.14039891958236694, -3.314793586730957, -3.4222517013549805, -4.174323081970215, -4.618517875671387, -5.667183876037598, -5.7096357345581055, -5.8034563064575195, -5.9185285568237305, -6.2669572830200195], [-0.7475233674049377, -1.2526845932006836, -2.3190431594848633, -2.5801897048950195, -4.059269905090332, -5.57285213470459, -5.901691436767578, -6.033797264099121, -6.035998344421387, -6.250855445861816], [-1.8844163417816162, -2.2718636989593506, -2.412362813949585, -2.5214059352874756, -2.7393338680267334, -3.0073068141937256, -3.3974931240081787, -3.5563371181488037, -3.614703893661499, -3.74259352684021], [-0.3305143117904663, -1.5365403890609741, -4.15228796005249, -4.9081645011901855, -4.944274425506592, -5.190614223480225, -5.326413631439209, -5.790236949920654, -6.089351177215576, -6.248103618621826], [-2.528672695159912, -2.5870862007141113, -2.706368923187256, -3.5319762229919434, -3.7567028999328613, -3.7633557319641113, -3.788112163543701, -3.833291530609131, -3.836548328399658, -3.8588614463806152], [-1.2825859785079956, -1.7136505842208862, -2.513422966003418, -2.55928897857666, -3.1831626892089844, -3.280745506286621, -3.309048652648926, -4.035722732543945, -4.5776872634887695, -4.58123779296875], [-0.5874870419502258, -1.6126868724822998, -2.7326438426971436, -3.131474256515503, -3.626375913619995, -4.418826103210449, -4.4205732345581055, -4.496153831481934, -4.67331600189209, -4.7862138748168945], [-1.5429555177688599, -2.386068344116211, -2.802579879760742, -2.947275161743164, -3.407024383544922, -3.643186569213867, -3.718541145324707, -3.7893543243408203, -3.9106884002685547, -4.092996597290039]], \"topKTokens\": [[\"\\n\", \",\", \"Words\", \"Summary\", \"\\n\\n\", \"<|endoftext|>\", \" \", \"Features\", \"Random\", \" the\"], [\" upon\", \" there\", \",\", \" the\", \" she\", \" on\", \" he\", \" day\", \" in\", \" night\"], [\" a\", \" an\", \" the\", \" one\", \" time\", \" some\", \" upon\", \" it\", \" two\", \" something\"], [\" time\", \" day\", \" night\", \" morning\", \" week\", \" Sunday\", \" long\", \" Wednesday\", \" dark\", \" little\"], [\",\", \" there\", \" in\", \" a\", \" was\", \" upon\", \".\", \" on\", \" the\", \" lived\"], [\" there\", \" a\", \" in\", \" two\", \" the\", \" she\", \" it\", \" Jack\", \" he\", \" Sam\"], [\" was\", \" were\", \" lived\", \" are\", \" is\", \"'s\", \",\", \" a\", \" wasn\", \" had\"], [\" two\", \" three\", \" a\", \" four\", \" twin\", \" many\", \" little\", \" an\", \" some\", \" baby\"], [\" friends\", \" best\", \" brothers\", \" little\", \" children\", \" sisters\", \" kids\", \" boys\", \" twins\", \" brave\"], [\" friends\", \" pals\", \" buddies\", \" best\", \" brothers\", \" twin\", \" children\", \" sisters\", \" fish\", \" girls\"], [\".\", \",\", \" named\", \" who\", \" called\", \" -\", \":\", \" and\", \" \\u2013\", \";\"], [\" a\", \" Jack\", \" Tom\", \" John\", \" Tim\", \" Lucy\", \" Bob\", \" Sam\", \" Jane\", \" Molly\"], [\" and\", \".\", \",\", \" was\", \"y\", \" -\", \"'s\", \"!\", \" had\", \" wanted\"], [\" to\", \" playing\", \" going\", \" exploring\", \" chocolate\", \" the\", \" fashion\", \" her\", \" popcorn\", \" spending\"], [\" play\", \" explore\", \" go\", \" swim\", \" dance\", \" race\", \" sing\", \" eat\", \" travel\", \" run\"], [\".\", \" down\", \" in\", \"!\", \" and\", \",\", \" on\", \" together\", \" around\", \" at\"], [\" the\", \" a\", \" her\", \" hills\", \" it\", \".\", \" on\", \" their\", \" in\", \" together\"], [\" hill\", \" big\", \" slide\", \" stairs\", \" street\", \" playground\", \" slides\", \" park\", \" icy\", \" hills\"], [\".\", \" and\", \" on\", \" near\", \" together\", \" in\", \",\", \"!\", \" every\", \" with\"], [\" Every\", \" She\", \" One\", \"\\n\", \" They\", \" \", \" It\", \" Whenever\", \" Jane\", \" The\"], [\" day\", \" morning\", \" night\", \" time\", \" summer\", \" year\", \" week\", \" winter\", \" weekend\", \" spring\"], [\",\", \" she\", \" they\", \" the\", \" Jane\", \" at\", \" when\", \" after\", \" it\", \" was\"], [\" they\", \" she\", \" Jane\", \" the\", \" when\", \" her\", \" it\", \" after\", \" their\", \" Jack\"], [\" would\", \" went\", \" played\", \"'d\", \" liked\", \" loved\", \" slid\", \" were\", \" had\", \" enjoyed\"], [\" go\", \" slide\", \" play\", \" climb\", \" run\", \" race\", \" take\", \" come\", \" have\", \" explore\"], [\" to\", \" out\", \" on\", \" up\", \" and\", \" down\", \" outside\", \" for\", \" sliding\", \" there\"], [\" the\", \" their\", \" a\", \" different\", \" slide\", \" her\", \" play\", \" explore\", \" school\", \" an\"], [\" park\", \" top\", \" mountain\", \" beach\", \" river\", \" lake\", \" same\", \" bottom\", \" playground\", \" slide\"], [\" and\", \" to\", \" together\", \",\", \" near\", \".\", \" with\", \" on\", \" in\", \" nearby\"], [\" slide\", \" play\", \" swim\", \" see\", \" have\", \" go\", \" explore\", \" cool\", \" get\", \" watch\"], [\".\", \" and\", \" on\", \" in\", \" together\", \",\", \" with\", \" games\", \" a\", \" near\"], [\" the\", \" their\", \".\", \" it\", \" and\", \" its\", \" a\", \",\", \" all\", \" one\"], [\" slide\", \" slides\", \" mountain\", \" swings\", \" shore\", \" beach\", \" other\", \" sand\", \" ice\", \" icy\"], [\".\", \" and\", \",\", \" together\", \" with\", \" -\", \"!\", \" in\", \" at\", \" again\"], [\" the\", \" their\", \".\", \" a\", \" and\", \" her\", \" it\", \" its\", \" peace\", \" different\"], [\" water\", \" sand\", \" park\", \" cool\", \" lake\", \" snow\", \" wet\", \" mud\", \" pool\", \" sun\"], [\" water\", \",\", \" lake\", \" river\", \" breeze\", \" pool\", \" ocean\", \" waves\", \" air\", \" sand\"], [\".\", \",\", \" and\", \" on\", \"!\", \" at\", \" with\", \" below\", \" when\", \" near\"], [\"\\n\", \" \", \" One\", \" They\", \" Jane\", \" It\", \" But\", \" The\", \" Sometimes\", \" Then\"], [\" day\", \" sunny\", \" summer\", \" time\", \" cold\", \" morning\", \" afternoon\", \" hot\", \" of\", \" night\"], [\",\", \" they\", \" Jane\", \" the\", \" when\", \" while\", \" a\", \" she\", \" two\", \" it\"], [\" they\", \" Jane\", \" when\", \" the\", \" a\", \" while\", \" as\", \" it\", \" two\", \" something\"], [\" was\", \" and\", \" wanted\", \" decided\", \"'s\", \" saw\", \" had\", \" noticed\", \" found\", \" went\"], [\" her\", \" the\", \" them\", \" a\", \" all\", \" Jane\", \" everyone\", \" it\", \" him\", \" something\"], [\" other\", \" slide\", \" friends\", \" mountain\", \" kids\", \" lake\", \" biggest\", \" girl\", \" ducks\", \" funn\"], [\",\", \" that\", \" she\", \" to\", \" so\", \" was\", \" about\", \" and\", \" a\", \" with\"], [\" \\\"\", \" \\ufffd\", \" but\", \" and\", \" so\", \" '\", \" it\", \" the\", \" a\", \" she\"], [\" she\", \" it\", \" the\", \" Jane\", \" when\", \" her\", \" something\", \" first\", \" there\", \" this\"], [\" mom\", \" friends\", \" friend\", \" parents\", \" mum\", \" hands\", \" feet\", \" dad\", \" shoes\", \" slide\"], [\" brother\", \" legs\", \" boy\", \" feet\", \" sister\", \" hands\", \" slide\", \" lungs\", \" girl\", \" friend\"], [\" was\", \" wanted\", \" wouldn\", \" said\", \" Tom\", \" didn\", \" Joe\", \" Jack\", \" disagreed\", \" did\"], [\" too\", \" not\", \" scared\", \" being\", \" feeling\", \" very\", \" worried\", \" so\", \" there\", \" brave\"], [\"beh\", \"chie\", \"be\", \"assy\", \"ol\", \"so\", \"very\", \"ere\", \"t\", \"eful\"], [\"aving\", \"beh\", \"aved\", \"ching\", \"au\", \"patient\", \"umpy\", \"arre\", \"istent\", \"rowing\"], [\".\", \" and\", \",\", \"!\", \" in\", \" when\", \" because\", \" at\", \" on\", \" too\"], [\" He\", \" Jane\", \" She\", \"\\n\", \" \", \" His\", \" The\", \" Her\", \" So\", \" \\\"\"], [\" was\", \" said\", \" didn\", \" told\", \" wanted\", \" started\", \" kept\", \" would\", \" wouldn\", \" did\"], [\" to\", \" pushing\", \" shouting\", \" playing\", \" jumping\", \" sliding\", \" running\", \" screaming\", \" climbing\", \" behaving\"], [\" and\", \" loudly\", \",\", \" at\", \" really\", \" with\", \" very\", \" for\", \" because\", \".\"], [\" pushing\", \" jumping\", \" crying\", \" running\", \" spl\", \" kicking\", \" shaking\", \" shouting\", \" screaming\", \" Jane\"], [\" around\", \" away\", \" to\", \" down\", \".\", \" towards\", \",\", \" out\", \" very\", \" as\"], [\" the\", \".\", \",\", \" in\", \" and\", \" with\", \" until\", \" on\", \" her\", \" to\"], [\" circles\", \" the\", \" a\", \" pain\", \" his\", \" excitement\", \" fear\", \" her\", \" joy\", \" Jane\"], [\".\", \",\", \" and\", \"!\", \" in\", \" until\", \" with\", \" on\", \" without\", \" all\"], [\" Jane\", \"\\n\", \" \", \" He\", \" His\", \" The\", \" Suddenly\", \" Everyone\", \" Her\", \" But\"], [\" was\", \" got\", \" didn\", \" felt\", \" knew\", \" wanted\", \" and\", \" tried\", \"'s\", \" laughed\"], [\" angry\", \" very\", \" so\", \" mad\", \" scared\", \" upset\", \" really\", \" worried\", \" frustrated\", \" too\"], [\" and\", \",\", \" at\", \".\", \" because\", \" so\", \" when\", \" but\", \"!\", \" that\"], [\" she\", \" her\", \" he\", \" the\", \" they\", \" him\", \" much\", \" a\", \" Jane\", \" loud\"], [\" ran\", \" slid\", \" told\", \" tried\", \" started\", \" shouted\", \" chased\", \" pushed\", \" watched\", \" went\"], [\" to\", \" the\", \" her\", \" sliding\", \" playing\", \" that\", \" this\", \" him\", \" being\", \" it\"], [\" slide\", \" and\", \" time\", \",\", \" game\", \".\", \" new\", \" way\", \" so\", \"!\"], [\" and\", \".\", \",\", \"!\", \" -\", \" but\", \" because\", \" of\", \";\", \" so\"], [\"\\n\", \" She\", \" \", \" Suddenly\", \" He\", \" Jane\", \" But\", \" Her\", \" So\", \" Then\"], [\",\", \" she\", \" enough\", \" the\", \" Jane\", \" he\", \" they\", \" after\", \" it\", \" all\"], [\" was\", \" realised\", \" realized\", \" started\", \" saw\", \" got\", \" came\", \" noticed\", \" heard\", \" found\"], [\" so\", \" very\", \" tired\", \" to\", \" an\", \" really\", \" too\", \" mad\", \" angry\", \" a\"], [\" angry\", \" tired\", \" mad\", \" upset\", \" dizz\", \" sick\", \" wet\", \" cross\", \" scared\", \" boss\"], [\" and\", \".\", \",\", \" at\", \" with\", \" when\", \" because\", \"!\", \" that\", \" so\"], [\" shouted\", \" yelled\", \" started\", \" told\", \" said\", \" she\", \" decided\", \" stopped\", \" ran\", \" tried\"], [\" to\", \" shouting\", \" yelling\", \" screaming\", \" throwing\", \" crying\", \" chasing\", \" pushing\", \" running\", \" hitting\"], [\" cry\", \" yell\", \" shout\", \" scream\", \" fight\", \" stomp\", \" push\", \" chase\", \" run\", \" throw\"], [\" at\", \".\", \" and\", \",\", \"!\", \" loudly\", \" louder\", \" her\", \" too\", \" even\"], [\" \\\"\", \" \\ufffd\", \" but\", \" '\", \" telling\", \" so\", \" louder\", \" making\", \" she\", \" too\"], [\"Stop\", \"No\", \"You\", \"I\", \"Why\", \"Give\", \"Go\", \"That\", \"Jane\", \"Hey\"], [\" are\", \" did\", \" is\", \" do\", \" can\", \" won\", \" don\", \" were\", \"?!\\\"\", \" didn\"], [\" you\", \" I\", \" the\", \" we\", \" your\", \" so\", \" those\", \" it\", \" my\", \" ya\"], [\" screaming\", \" shouting\", \" yelling\", \" so\", \" angry\", \" mad\", \" being\", \" behaving\", \" upset\", \" fighting\"], [\"?\\\".\", \"?\\\"\", \"?\", \"?!\\\"\", \",\", \" at\", \"?!\", \"!?\\\"\", \" so\", \" and\"], [\"\\n\", \" Jane\", \" \", \" Her\", \" She\", \" But\", \" The\", \" Suddenly\", \" she\", \" her\"], [\"my\", \" was\", \" said\", \" shouted\", \" felt\", \" replied\", \" didn\", \" heard\", \" told\", \" just\"], [\".\", \",\", \" back\", \" and\", \" \\\"\", \" in\", \" at\", \" as\", \" again\", \" loudly\"], [\" Jane\", \"\\n\", \" \\\"\", \" He\", \" \", \" The\", \" His\", \" But\", \" Tim\", \" So\"], [\" was\", \" said\", \" didn\", \" ran\", \" told\", \" felt\", \" wanted\", \" replied\", \" shouted\", \" had\"], [\" his\", \" her\", \" the\", \" himself\", \" Jane\", \" and\", \" off\", \" so\", \" them\", \" back\"], [\" head\", \" fists\", \" fist\", \" body\", \" ears\", \" voice\", \" arms\", \" hand\", \" feet\", \" hands\"], [\" at\", \" and\", \" in\", \",\", \" up\", \" as\", \" hard\", \" again\", \" into\", \" on\"], [\" her\", \" Jane\", \" the\", \" his\", \" him\", \" Amy\", \" everyone\", \" one\", \" them\", \" Tim\"], [\" and\", \",\", \".\", \" to\", \" with\", \"'s\", \" until\", \" because\", \" in\", \" but\"], [\" said\", \" she\", \" told\", \" then\", \" shouted\", \" asked\", \" he\", \" they\", \" her\", \" tried\"], [\",\", \" \\\"\", \" he\", \" nothing\", \" she\", \" that\", \" they\", \" it\", \" in\", \" to\"], [\" \\\"\", \" \\ufffd\", \" '\", \"\\n\", \" \", \" \\\"'\", \" ''\", \" but\", \"\\ufffd\", \" \\\"\\\"\"], [\"I\", \"because\", \"You\", \"Because\", \"you\", \"That\", \"It\", \"it\", \"No\", \"We\"], [\"'m\", \" don\", \" want\", \" am\", \" just\", \" hate\", \" was\", \" wanted\", \" didn\", \" think\"], [\"'t\", \"\\ufffd\", \"'\", \"\\u00b4\", \" it\", \"`\", \" too\", \"t\", \"\\n\", \" something\"], [\" want\", \" mean\", \" like\", \" know\", \" get\", \" behave\", \" scream\", \"!\\\"\", \" shout\", \"!\"], [\" it\", \" the\", \" I\", \" that\", \" this\", \" you\", \",\", \" how\", \".\", \"!\\\"\"], [\" was\", \" would\", \"'s\", \"!\\\"\", \" wasn\", \" is\", \"!\\\".\", \",\", \" could\", \" made\"], [\" so\", \" a\", \" yours\", \" your\", \" me\", \" bad\", \" wrong\", \" you\", \" important\", \" too\"], [\" a\", \" very\", \" an\", \" really\", \" me\", \" bad\", \" Tim\", \" quite\", \" your\", \" fun\"], [\".\", \"!\\\"\", \"\\\".\", \".\\\"\", \",\", \"!\", \"!\\\".\", \" because\", \" and\", \" at\"], [\" I\", \" It\", \" Let\", \" You\", \" Please\", \" We\", \" Now\", \" Can\", \" But\", \" What\"], [\" were\", \" should\", \" must\", \" are\", \" just\", \" have\", \" scared\", \"'re\", \" can\", \" need\"], [\" have\", \" get\", \" hurt\", \" never\", \" break\", \" tell\", \" make\", \" ruin\", \" do\", \" start\"], [\" hurt\", \" gotten\", \" been\", \" caused\", \" started\", \" done\", \" broken\", \" ruined\", \" made\", \" taken\"], [\" me\", \" yourself\", \" someone\", \" yourselves\", \" Jane\", \" the\", \" us\", \" my\", \" people\", \" Tim\"], [\"!\\\"\", \".\\\"\", \"\\\".\", \"!\", \".\", \" and\", \"!\\\".\", \" or\", \",\", \" if\"], [\" Jane\", \"\\n\", \" Tim\", \" \", \" The\", \" But\", \" Then\", \" And\", \" That\", \" He\"], [\" was\", \" felt\", \" thought\", \" just\", \" said\", \" apologized\", \" didn\", \" quickly\", \" and\", \" stopped\"], [\" so\", \" very\", \" scared\", \" sad\", \" surprised\", \" really\", \" sorry\", \" still\", \" shocked\", \" embarrassed\"], [\" scared\", \" sorry\", \" sad\", \" mad\", \" surprised\", \" upset\", \" really\", \" embarrassed\", \" hurt\", \" angry\"], [\" and\", \".\", \",\", \" with\", \" but\", \" because\", \" that\", \" now\", \" so\", \" about\"], [\" Jane\", \"\\n\", \" \", \" She\", \" Tim\", \" But\", \" He\", \" Then\", \" They\", \" From\"], [\" felt\", \" was\", \" thought\", \" looked\", \" didn\", \" knew\", \" had\", \" said\", \" stopped\", \" smiled\"], [\" bad\", \" sorry\", \" very\", \" so\", \" sad\", \" really\", \" guilty\", \" embarrassed\", \" ashamed\", \" scared\"], [\" and\", \" for\", \",\", \" but\", \" too\", \" that\", \".\", \" so\", \" about\", \" because\"], [\" shouting\", \" yelling\", \" making\", \" being\", \" Tim\", \" her\", \" what\", \" him\", \" not\", \" sc\"], [\" so\", \" scared\", \" mean\", \" mad\", \" angry\", \" naughty\", \" boss\", \" bad\", \" upset\", \" spoiled\"], [\" rude\", \" bad\", \" harsh\", \" selfish\", \" mean\", \" naughty\", \" sorry\", \" scared\", \" hurt\", \" sad\"], [\" and\", \".\", \",\", \" but\", \" so\", \" too\", \" at\", \" to\", \" in\", \" by\"], [\" apologised\", \" said\", \" she\", \" promised\", \" apologized\", \" he\", \" decided\", \" ran\", \" started\", \" shouted\"], [\" said\", \" apologised\", \" promised\", \" started\", \" apologized\", \" had\", \" decided\", \" knew\", \" was\", \" wanted\"], [\" she\", \" he\", \" that\", \" it\", \" the\", \" what\", \" Tim\", \" how\", \" her\", \" they\"], [\" had\", \" was\", \" should\", \" needed\", \" would\", \" shouldn\", \" did\", \" didn\", \" must\", \" could\"], [\" wrong\", \" sorry\", \" right\", \" in\", \" being\", \" not\", \" never\", \" just\", \" going\", \" her\"], [\".\", \" to\", \",\", \" and\", \" for\", \" too\", \" again\", \" but\", \" with\", \" about\"], [\" She\", \" He\", \"\\n\", \" So\", \" From\", \" \", \" Jane\", \" Tim\", \" After\", \" But\"], [\" hugged\", \" both\", \" went\", \" said\", \" decided\", \" promised\", \" had\", \" ran\", \" quickly\", \" started\"], [\" the\", \" her\", \" away\", \" a\", \" Tim\", \" him\", \" their\", \" Jane\", \" off\", \" turns\"], [\" the\", \" their\", \" all\", \" Jane\", \" her\", \" his\", \" running\", \" Tim\", \" and\", \" to\"], [\" slide\", \" wet\", \" bath\", \" mountain\", \" beach\", \" swing\", \" warm\", \" water\", \" boots\", \" pain\"], [\" and\", \",\", \" together\", \" from\", \" to\", \" in\", \" the\", \" again\", \" home\", \" at\"], [\" promised\", \" said\", \" the\", \" gave\", \" put\", \" went\", \" apologised\", \" Jane\", \" hugged\", \" had\"], [\" her\", \" their\", \" Jane\", \" Tim\", \" the\", \" him\", \" each\", \" his\", \" everyone\", \" mom\"], [\" that\", \" to\", \" brother\", \" it\", \" he\", \" she\", \" they\", \" what\", \" the\", \" mom\"], [\" it\", \" she\", \" they\", \" he\", \" the\", \" if\", \" shouting\", \" screaming\", \" Jane\", \" everything\"], [\" was\", \" wasn\", \"'s\", \" would\", \" wouldn\", \" had\", \" didn\", \" is\", \"\\ufffd\", \" made\"], [\" not\", \" ok\", \" time\", \" okay\", \" wrong\", \" important\", \" better\", \" OK\", \" alright\", \" a\"], [\" bad\", \" very\", \" good\", \" lesson\", \" special\", \" time\", \" waste\", \" punishment\", \" way\", \" big\"], [\" thing\", \" idea\", \" ending\", \" way\", \" day\", \" experience\", \" result\", \" fight\", \" choice\", \" punishment\"], [\".\", \" to\", \" and\", \",\", \" of\", \" because\", \" for\", \" that\", \" they\", \" she\"], [\" They\", \" She\", \" Jane\", \"\\n\", \" He\", \" So\", \" \", \" From\", \" The\", \" Tim\"], [\" both\", \" said\", \" went\", \" decided\", \" would\", \" hugged\", \" made\", \" could\", \" had\", \" ran\"], [\" they\", \",\", \" that\", \" it\", \" to\", \" sorry\", \" \\\"\", \" she\", \" '\", \" the\"], [\" '\", \" \\\"\", \" \\ufffd\", \" they\", \"\\n\", \" \", \" ''\", \" that\", \" in\", \" if\"], [\"Let\", \"We\", \"If\", \"It\", \"I\", \"That\", \"You\", \"let\", \"Why\", \"No\"], [\"'s\", \"\\ufffd\", \" me\", \" us\", \"'\", \" the\", \" go\", \"\\u00b4\", \" it\", \"ting\"], [\" go\", \" make\", \" all\", \" play\", \" both\", \" share\", \" do\", \" not\", \" tell\", \" just\"], [\" to\", \" down\", \" on\", \" and\", \" get\", \" home\", \" slide\", \" find\", \" back\", \" the\"], [\" the\", \" together\", \" and\", \" to\", \" this\", \"'\", \" slowly\", \" that\", \" a\", \" it\"], [\" slide\", \" hill\", \" mountain\", \" stairs\", \" slides\", \" big\", \" river\", \" lake\", \" ladder\", \" path\"], [\" together\", \" and\", \",\", \" instead\", \"!'\", \"'.\", \".\", \" at\", \"'\", \" backwards\"], [\" and\", \",\", \".\", \"!'\", \"!\", \"'.\", \" so\", \" in\", \"\\\".\", \" to\"], [\" time\", \" way\", \" weekend\", \" day\", \" morning\", \" afternoon\", \" week\", \" year\", \" evening\", \" slide\"], [\",\", \" and\", \"'.\", \".\", \"!'\", \"!\", \"\\\".\", \".'\", \"!\\\"\", \" so\"], [\"'.\", \" That\", \" You\", \" It\", \" We\", \" I\", \"',\", \"\\ufffd\", \" Let\", \" The\"], [\" Jane\", \"\\n\", \" \", \" So\", \" Tim\", \" They\", \" The\", \" And\", \" That\", \" Everyone\"], [\" was\", \" smiled\", \" thought\", \" and\", \" agreed\", \" nodded\", \" liked\", \" did\", \" felt\", \" said\"], [\" so\", \" very\", \" happy\", \" scared\", \" really\", \" surprised\", \" still\", \" relieved\", \" excited\", \" a\"], [\" scared\", \" upset\", \" angry\", \" a\", \" very\", \" sad\", \" mad\", \" feeling\", \" so\", \" really\"], [\",\", \" and\", \" but\", \".\", \" of\", \" so\", \" as\", \" by\", \" at\", \" when\"], [\" she\", \" started\", \" ran\", \" screamed\", \" didn\", \" quickly\", \" shouted\", \" Tim\", \" did\", \" tried\"], [\" Tim\", \" if\", \",\", \" why\", \" her\", \" \\\"\", \" what\", \" the\", \" Jane\", \" for\"], [\" she\", \" they\", \" Tim\", \" the\", \" it\", \" that\", \" anyone\", \" he\", \" there\", \" Jane\"], [\" could\", \" would\", \" wanted\", \" was\", \" had\", \" saw\", \" couldn\", \" didn\", \" did\", \"'d\"], [\" forgive\", \" be\", \" like\", \" help\", \" go\", \" do\", \" make\", \" feel\", \" come\", \" let\"], [\" Tim\", \" him\", \" her\", \" them\", \" the\", \".\", \" Tom\", \" herself\", \" anyone\", \" it\"], [\".\", \",\", \" but\", \" and\", \" for\", \" if\", \" with\", \" too\", \" again\", \" he\"], [\" Tim\", \"\\n\", \" She\", \" The\", \" But\", \" Jane\", \" He\", \" \", \" They\", \" To\"], [\",\", \" they\", \" her\", \" she\", \" the\", \" it\", \" Jane\", \" their\", \" that\", \" a\"], [\" were\", \" did\", \" agreed\", \" both\", \" had\", \" heard\", \" hugged\", \" decided\", \" would\", \" said\"], [\" to\", \" not\", \" it\", \" that\", \" never\", \" they\", \",\", \" she\", \" no\", \" he\"], [\" be\", \" go\", \" forgive\", \" give\", \" help\", \" stay\", \" try\", \" take\", \" leave\", \" tell\"], [\" to\", \" about\", \" it\", \" and\", \".\", \" the\", \" instead\", \" calmly\", \",\", \" with\"], [\" as\", \" like\", \" in\", \" before\", \" to\", \" for\", \" being\", \" how\", \" with\", \" the\"], [\" they\", \" she\", \" the\", \" he\", \" their\", \" it\", \" and\", \" her\", \" Jane\", \" sliding\"], [\".\", \" mom\", \" brother\", \" and\", \" mum\", \" friend\", \",\", \" parents\", \" big\", \" little\"], [\".\", \" and\", \",\", \" time\", \" of\", \" first\", \" so\", \" in\", \" was\", \" for\"], [\"\\n\", \" Jane\", \" They\", \" \", \" She\", \" When\", \" Tim\", \" And\", \" After\", \" So\"], [\"\\n\", \"<|endoftext|>\", \"Summary\", \"When\", \"Tim\", \"Jane\", \"So\", \"They\", \" \", \"The\"], [\"When\", \"Tim\", \"Jane\", \"The\", \"So\", \"They\", \"After\", \"At\", \"Once\", \"To\"], [\" dinner\", \" that\", \" they\", \" a\", \"wards\", \" the\", \" some\", \" lunch\", \" eating\", \" she\"], [\" had\", \" finished\", \" were\", \" ate\", \" said\", \" calmed\", \" made\", \" got\", \" both\", \" talked\"], [\" at\", \" around\", \" out\", \" away\", \" for\", \" in\", \" outside\", \" back\", \" up\", \" down\"], [\" a\", \" dinner\", \" some\", \" the\", \" an\", \" hours\", \" what\", \" their\", \" awhile\", \" Jane\"], [\" while\", \" few\", \" way\", \" moment\", \" little\", \" long\", \" bit\", \" minute\", \" second\", \" good\"], [\",\", \" and\", \" they\", \" longer\", \" Jane\", \" the\", \".\", \" in\", \" about\", \" of\"], [\" Jane\", \" they\", \" Tim\", \" the\", \" it\", \" then\", \" and\", \" she\", \" their\", \" but\"], [\" both\", \" found\", \" finally\", \" decided\", \" saw\", \" said\", \" realized\", \" heard\", \" realised\", \" agreed\"], [\" the\", \" a\", \" their\", \" into\", \" for\", \" Jane\", \" an\", \" out\", \" safety\", \" her\"], [\" big\", \" beautiful\", \" safe\", \" nearby\", \" magical\", \" special\", \" clearing\", \" secret\", \" park\", \" bench\"], [\"-\", \" and\", \" distance\", \",\", \" shop\", \" way\", \" time\", \" agreement\", \" hill\", \" path\"], [\".\", \" and\", \" that\", \" in\", \",\", \" to\", \" at\", \" with\", \" where\", \" near\"], [\" the\", \" shouted\", \" Jane\", \" were\", \" got\", \" had\", \" there\", \" bought\", \" said\", \" decided\"]], \"correctTokenRank\": [294, 0, 0, 0, 0, 0, 1, 0, 1, 0, 5, 8, 17, 0, 39, 1, 0, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 1, 2, 0, 0, 7, 0, 3, 0, 0, 2, 0, 0, 1, 28, 1, 1, 0, 2, 5, 39, 0, 0, 226, 0, 0, 0, 0, 5, 7, 0, 3, 0, 3, 0, 0, 0, 1, 3, 14, 0, 145, 6, 7, 1, 16, 1, 5, 1, 0, 0, 2, 0, 2, 3, 0, 70, 0, 0, 0, 1, 102, 3, 0, 3, 33, 0, 1, 0, 1, 0, 0, 0, 0, 0, 8, 0, 3, 0, 0, 146, 25, 0, 3, 14, 0, 0, 0, 19, 2, 0, 5, 23, 18, 0, 0, 0, 1, 3, 45, 5, 0, 2, 7, 1, 1, 0, 0, 10, 15, 8, 0, 0, 0, 19, 0, 0, 0, 0, 9, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 32, 0, 5, 0, 0, 0, 6, 35, 1, 12, 1, 0, 1, 0, 1, 0, 25, 1, 7, 0, 22, 50, 3, 7, 108, 0, 0, 0, 6, 2, 51, 4, 0, 0, 0, 1, 15, 1, 1353, 4, 1, 2], \"correctTokenLogProb\": [-11.625466346740723, -0.37248945236206055, -0.005904730875045061, -0.011737806722521782, -0.18781840801239014, -0.10250551998615265, -2.5443296432495117, -0.18424437940120697, -1.3947784900665283, -0.0043445490300655365, -3.4880740642547607, -4.210378170013428, -8.965112686157227, -0.4294908046722412, -5.466840744018555, -1.4784069061279297, -0.5296363830566406, -6.283028602600098, -0.4805505871772766, -1.37201988697052, -0.15148471295833588, -0.9233695268630981, -0.7494935989379883, -0.14666730165481567, -0.9950123429298401, -0.7579677700996399, -0.059422604739665985, -3.488163948059082, -1.5202195644378662, -1.6613528728485107, -1.7359129190444946, -0.1833234429359436, -0.7464687824249268, -6.1217942237854, -0.16442151367664337, -2.6173694133758545, -0.5157206058502197, -0.09311053901910782, -2.9140207767486572, -0.029738498851656914, -0.08854794502258301, -1.817314624786377, -5.875592231750488, -2.675489902496338, -2.0851011276245117, -1.0439530611038208, -3.5728671550750732, -3.3148200511932373, -5.98094367980957, -0.1891482025384903, -1.8769748210906982, -8.819160461425781, -0.6766725778579712, -0.007602449040859938, -0.32608187198638916, -0.6246393918991089, -3.2841854095458984, -5.153570652008057, -0.39497438073158264, -2.631153106689453, -0.3752288520336151, -2.5565145015716553, -0.5688799619674683, -0.5999304056167603, -0.34991395473480225, -2.2631959915161133, -2.1894760131835938, -7.556927680969238, -0.2266160398721695, -8.010269165039062, -3.325014591217041, -3.6705522537231445, -1.374091625213623, -5.626761436462402, -2.1110920906066895, -3.526754856109619, -2.09171724319458, -1.3395881652832031, -0.37545686960220337, -2.083096504211426, -0.805349588394165, -2.049063205718994, -2.8785157203674316, -0.1928037703037262, -7.403348922729492, -0.5717241764068604, -0.0025132279843091965, -1.1006380319595337, -1.4605408906936646, -9.072646141052246, -2.5454940795898438, -0.7252607345581055, -2.659871816635132, -6.0885233879089355, -0.1665811538696289, -3.1266391277313232, -1.0154649019241333, -1.0131678581237793, -0.5162434577941895, -0.5815250873565674, -0.49372515082359314, -0.01076321117579937, -1.2943432331085205, -4.9065470695495605, -0.0034656007774174213, -2.68467378616333, -1.6599316596984863, -0.307251513004303, -8.3024263381958, -5.16568660736084, -1.2542147636413574, -2.8687591552734375, -4.476164817810059, -0.26797130703926086, -0.7595131397247314, -0.5377371907234192, -5.790265083312988, -2.1719937324523926, -0.9734164476394653, -3.1884236335754395, -6.681902885437012, -6.565891742706299, -0.8649066686630249, -1.3653086423873901, -1.065718650817871, -1.2790391445159912, -2.5077390670776367, -8.25623893737793, -2.9046430587768555, -0.577147364616394, -2.3040027618408203, -3.3855135440826416, -2.0376768112182617, -1.518571376800537, -0.9947794079780579, -0.06083216518163681, -4.600437641143799, -4.899538516998291, -3.1549105644226074, -0.597136378288269, -0.3132166862487793, -0.16219192743301392, -4.377832412719727, -1.0941803455352783, -1.862054467201233, -1.4229860305786133, -0.26988038420677185, -4.258707046508789, -0.9529871940612793, -1.4841923713684082, -0.4911348521709442, -1.6362488269805908, -2.4345998764038086, -1.8487093448638916, -0.6430174708366394, -1.0419840812683105, -0.03742760792374611, -0.9128149747848511, -1.3982164859771729, -0.41720911860466003, -0.05869555473327637, -0.5204674005508423, -6.314140796661377, -0.08036521822214127, -2.5829031467437744, -0.9169183373451233, -0.9686422944068909, -1.149220585823059, -3.7197136878967285, -6.54740047454834, -1.7820441722869873, -3.8164749145507812, -2.6985573768615723, -0.8807977437973022, -1.9334362745285034, -1.970598578453064, -1.1930229663848877, -0.4844643175601959, -5.802218914031982, -3.8833441734313965, -3.5794878005981445, -0.5657970309257507, -4.707070827484131, -7.5915422439575195, -2.6254146099090576, -3.529468536376953, -7.740997314453125, -0.4409850537776947, -1.168308973312378, -0.6876299977302551, -3.1038055419921875, -2.215435266494751, -6.560124397277832, -3.4652366638183594, -0.1302422136068344, -0.8037805557250977, -0.14039891958236694, -1.2526845932006836, -4.4100341796875, -1.5365403890609741, -11.101373672485352, -3.1831626892089844, -1.6126868724822998, -2.802579879760742]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x266af62bf20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = model.generate(\n",
    "    \"Once upon a time\",\n",
    "    stop_at_eos=False,  # avoids a bug on MPS\n",
    "    temperature=1,\n",
    "    verbose=True,\n",
    "    max_new_tokens=200,\n",
    ")\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melianaive\u001b[0m (\u001b[33melianaive-research\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\elian\\Workspace\\SAEs\\SAELens\\wandb\\run-20241204_213437-cmmmpnco</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elianaive-research/sae_lens_tutorial/runs/cmmmpnco' target=\"_blank\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</a></strong> to <a href='https://wandb.ai/elianaive-research/sae_lens_tutorial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elianaive-research/sae_lens_tutorial' target=\"_blank\">https://wandb.ai/elianaive-research/sae_lens_tutorial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elianaive-research/sae_lens_tutorial/runs/cmmmpnco' target=\"_blank\">https://wandb.ai/elianaive-research/sae_lens_tutorial/runs/cmmmpnco</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SAE:   0%|          | 0/122880000 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Estimating norm scaling factor: 100%|██████████| 1000/1000 [00:34<00:00, 29.08it/s]\n",
      "19500| l1_loss: 162.81946 | mse_loss: 204.06320:  65%|██████▌   | 79872000/122880000 [58:51<43:00, 16665.98it/s]  interrupted, saving progress\n"
     ]
    },
    {
     "ename": "InterruptedException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInterruptedException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 62\u001b[0m\n\u001b[0;32m      9\u001b[0m cfg \u001b[38;5;241m=\u001b[39m LanguageModelSAERunnerConfig(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Data Generating Function (Model + Training Distibuion)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtiny-stories-1L-21M\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# look at the next cell to see some instruction for what to do while this is running.\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m sparse_autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mSAETrainingRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elian\\miniconda3\\Lib\\site-packages\\sae_lens\\sae_training_runner.py:113\u001b[0m, in \u001b[0;36mSAETrainingRunner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    104\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SAETrainer(\n\u001b[0;32m    105\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    106\u001b[0m     sae\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    109\u001b[0m     cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg,\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_if_needed()\n\u001b[1;32m--> 113\u001b[0m sae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trainer_with_interruption_handling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mlog_to_wandb:\n\u001b[0;32m    116\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[1;32mc:\\Users\\elian\\miniconda3\\Lib\\site-packages\\sae_lens\\sae_training_runner.py:156\u001b[0m, in \u001b[0;36mSAETrainingRunner.run_trainer_with_interruption_handling\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    153\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGTERM, interrupt_callback)\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# train SAE\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     sae \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, InterruptedException):\n\u001b[0;32m    159\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterrupted, saving progress\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elian\\miniconda3\\Lib\\site-packages\\sae_lens\\training\\sae_trainer.py:178\u001b[0m, in \u001b[0;36mSAETrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m layer_acts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_store\u001b[38;5;241m.\u001b[39mnext_batch()[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_training_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtrain_batch_size_tokens\n\u001b[1;32m--> 178\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43msae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_acts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mlog_to_wandb:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_train_step(step_output)\n",
      "File \u001b[1;32mc:\\Users\\elian\\miniconda3\\Lib\\site-packages\\sae_lens\\training\\sae_trainer.py:240\u001b[0m, in \u001b[0;36mSAETrainer._train_step\u001b[1;34m(self, sae, sae_in)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# for documentation on autocasting see:\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast_if_enabled:\n\u001b[0;32m    238\u001b[0m     train_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae\u001b[38;5;241m.\u001b[39mtraining_forward_pass(\n\u001b[0;32m    239\u001b[0m         sae_in\u001b[38;5;241m=\u001b[39msae_in,\n\u001b[1;32m--> 240\u001b[0m         dead_neuron_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdead_neurons\u001b[49m,\n\u001b[0;32m    241\u001b[0m         current_l1_coefficient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_l1_coefficient,\n\u001b[0;32m    242\u001b[0m     )\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    245\u001b[0m         did_fire \u001b[38;5;241m=\u001b[39m (train_step_output\u001b[38;5;241m.\u001b[39mfeature_acts \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\elian\\miniconda3\\Lib\\site-packages\\sae_lens\\training\\sae_trainer.py:164\u001b[0m, in \u001b[0;36mSAETrainer.dead_neurons\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdead_neurons\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_forward_passes_since_fired\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdead_feature_window\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elian\\miniconda3\\Lib\\site-packages\\sae_lens\\sae_training_runner.py:28\u001b[0m, in \u001b[0;36minterrupt_callback\u001b[1;34m(sig_num, stack_frame)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterrupt_callback\u001b[39m(sig_num: Any, stack_frame: Any):\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterruptedException()\n",
      "\u001b[1;31mInterruptedException\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19500| l1_loss: 162.81946 | mse_loss: 204.06320:  65%|██████▌   | 79872000/122880000 [59:03<43:00, 16665.98it/s]"
     ]
    }
   ],
   "source": [
    "total_training_steps = 30_000  # probably we should do more\n",
    "batch_size = 4096\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20  # 5% of training\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True,  # we could pre-download the token dataset if it was small.\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=\"expected_average_only_in\",\n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999,\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size_prompts=16,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_lens_tutorial\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder = SAETrainingRunner(cfg).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elian\\miniconda3\\Lib\\site-packages\\sae_lens\\training\\activations_store.py:267: RuntimeWarning: pretokenized dataset has context_size 512, but the provided context_size is 256. Some data will be discarded in this case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cmmmpnco) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▂▃▄▅███████████████████████████████████</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/l1_loss</td><td>▁█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>losses/mse_loss</td><td>█▂▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>▁▃▃▆█▆▆▆▅▅▅▅▅▅▅▅▅▅▄▅▄▄▄▄▄▄▄▄▄▃▄▃▄▃▃▃▄▃▃▃</td></tr><tr><td>losses/raw_l1_loss</td><td>▁▃▆▇████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>metrics/explained_variance</td><td>█▃▁▁▁▂▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▅▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>metrics/explained_variance_std</td><td>▁▂███▇▇▇█▇█▆▇▇▇▇▆▆▆▆▆▆▅▅▅▆▆▆▆▆▅▅▆▆▆▅▅▅▅▆</td></tr><tr><td>metrics/l0</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▁▃▆▆██████████████</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁▁▁▁▆▆██▆█████████</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▁▁▁▃▃▃▃▆▆▆██████▃▃▃▃▃▃▃▃▁</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▃▁▁▁▁▁▁▁▁▁▁▂▂▁▂▂▃▃▂▃▂▃▃▃▃▃▄▃▃▄▆▆▇█▅▃▄▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>5</td></tr><tr><td>details/current_learning_rate</td><td>5e-05</td></tr><tr><td>details/n_training_tokens</td><td>79872000</td></tr><tr><td>losses/l1_loss</td><td>32.56389</td></tr><tr><td>losses/mse_loss</td><td>204.0632</td></tr><tr><td>losses/overall_loss</td><td>366.88266</td></tr><tr><td>losses/raw_l1_loss</td><td>162.81946</td></tr><tr><td>metrics/explained_variance</td><td>0.65712</td></tr><tr><td>metrics/explained_variance_std</td><td>0.1333</td></tr><tr><td>metrics/l0</td><td>219.43701</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-2.59374</td></tr><tr><td>sparsity/below_1e-5</td><td>3</td></tr><tr><td>sparsity/below_1e-6</td><td>3</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>0.15735</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</strong> at: <a href='https://wandb.ai/elianaive-research/sae_lens_tutorial/runs/cmmmpnco' target=\"_blank\">https://wandb.ai/elianaive-research/sae_lens_tutorial/runs/cmmmpnco</a><br/> View project at: <a href='https://wandb.ai/elianaive-research/sae_lens_tutorial' target=\"_blank\">https://wandb.ai/elianaive-research/sae_lens_tutorial</a><br/>Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241204_213437-cmmmpnco\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cmmmpnco). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\elian\\Workspace\\SAEs\\SAELens\\wandb\\run-20241204_223444-pg3vgbic</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elianaive-research/gated_sae_testing/runs/pg3vgbic' target=\"_blank\">16384-L1-20-LR-5e-05-Tokens-1.229e+08</a></strong> to <a href='https://wandb.ai/elianaive-research/gated_sae_testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elianaive-research/gated_sae_testing' target=\"_blank\">https://wandb.ai/elianaive-research/gated_sae_testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elianaive-research/gated_sae_testing/runs/pg3vgbic' target=\"_blank\">https://wandb.ai/elianaive-research/gated_sae_testing/runs/pg3vgbic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[Ac:\\Users\\elian\\miniconda3\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2380: UserWarning: Run (cmmmpnco) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "19500| l1_loss: 162.81946 | mse_loss: 204.06320:  65%|██████▌   | 79872000/122880000 [1:00:28<32:33, 22013.08it/s]\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                                 \n",
      "Estimating norm scaling factor: 100%|██████████| 1000/1000 [01:54<00:00,  8.72it/s]\n",
      "30000| auxiliary_reconstruction_loss: 368.92831 | l1_loss: 329.27087 | mse_loss: 215.87946: 100%|██████████| 122880000/122880000 [1:11:55<00:00, 28475.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▂▃▃▄▆▆▆▆▆▇▇████████████████████████████</td></tr><tr><td>details/current_learning_rate</td><td>██████████████████████████████████████▃▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▃▃▄▅▅▅▅▅▆▆▆▆▇▇████████████████████████</td></tr><tr><td>losses/l1_loss</td><td>▅█▆▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>▁▁▁▁▂▅▅▅▆▆▆▆▇▇▇█████████████████████████</td></tr><tr><td>losses/overall_loss</td><td>▁▁▂▃▅▆▆▆▆▆▇█████████████████████████████</td></tr><tr><td>losses/raw_l1_loss</td><td>▁▁▄▅▅▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>metrics/explained_variance</td><td>▁██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>metrics/explained_variance_std</td><td>▂▁▁▃▃▄▄▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇█▇▇▇▇███▇██▇██████</td></tr><tr><td>metrics/l0</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▇▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▁▁▁▁▁▁▃▆▇█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁▁▁▁▁▁▁▁▂▄▆▇▇████████████████</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇█</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▆▆▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>20</td></tr><tr><td>details/current_learning_rate</td><td>0</td></tr><tr><td>details/n_training_tokens</td><td>122880000</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>368.92831</td></tr><tr><td>losses/l1_loss</td><td>16.46354</td></tr><tr><td>losses/mse_loss</td><td>215.87946</td></tr><tr><td>losses/overall_loss</td><td>914.07861</td></tr><tr><td>losses/raw_l1_loss</td><td>329.27087</td></tr><tr><td>metrics/explained_variance</td><td>0.63369</td></tr><tr><td>metrics/explained_variance_std</td><td>0.14129</td></tr><tr><td>metrics/l0</td><td>9.9458</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-4.08997</td></tr><tr><td>sparsity/below_1e-5</td><td>1226</td></tr><tr><td>sparsity/below_1e-6</td><td>915</td></tr><tr><td>sparsity/dead_features</td><td>572</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>115.23083</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">16384-L1-20-LR-5e-05-Tokens-1.229e+08</strong> at: <a href='https://wandb.ai/elianaive-research/gated_sae_testing/runs/pg3vgbic' target=\"_blank\">https://wandb.ai/elianaive-research/gated_sae_testing/runs/pg3vgbic</a><br/> View project at: <a href='https://wandb.ai/elianaive-research/gated_sae_testing' target=\"_blank\">https://wandb.ai/elianaive-research/gated_sae_testing</a><br/>Synced 4 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241204_223444-pg3vgbic\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_training_steps = 30_000  # probably we should do more\n",
    "batch_size = 4096\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
    "l1_warm_up_steps = 10_000  # total_training_steps // 20  # 5% of training\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distribution)\n",
    "    architecture=\"gated\",  # we'll use the gated variant.\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True,  # we could pre-download the token dataset if it was small.\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=True,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=False,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=\"expected_average_only_in\",\n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999,\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=20,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size_prompts=16,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"gated_sae_testing\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder = SAETrainingRunner(cfg).run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
